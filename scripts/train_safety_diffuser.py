# import torch
# import numpy as np
# import os
# import sys
# # MUJOCO_GL=egl /home/lqz27/anaconda3/envs/omnisafedd/bin/python /home/lqz27/dyx_ws/omnisafe/scripts/eval_diffuser.py

# # =================================================================
# # 1. è·¯å¾„è®¾ç½® (ç¡®ä¿ Python èƒ½æ‰¾åˆ° diffuser åŒ…)
# # =================================================================
# # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½• (.../omnisafe/scripts)
# current_dir = os.path.dirname(os.path.abspath(__file__))

# # è·å–é¡¹ç›®æ ¹ç›®å½• (.../omnisafe)
# project_root = os.path.dirname(current_dir)

# # å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path
# if project_root not in sys.path:
#     sys.path.append(project_root)

# print(f"âœ… å·²æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„: {project_root}")

# # å¼•å…¥ä½ çš„ adapter (å‡è®¾å®ƒåœ¨ scripts ç›®å½•ä¸‹)
# sys.path.append(current_dir) 

# try:
#     from dataset_adapter import SafetyGymDataset
# except ImportError:
#     print("âš ï¸ åœ¨å½“å‰ç›®å½•ä¸‹æ‰¾ä¸åˆ° dataset_adapterï¼Œå°è¯•ä»ä¸Šä¸€çº§æŸ¥æ‰¾...")
#     from scripts.dataset_adapter import SafetyGymDataset

# # =================================================================
# # 2. ã€æ ¸å¿ƒä¿®å¤ã€‘æ­£ç¡®çš„å¯¼å…¥æ–¹å¼
# # =================================================================
# # âŒ ä¸è¦ç”¨: from diffusion import GaussianDiffusion (è¿™æ˜¯æŠ¥é”™çš„åŸå› )
# # âœ… å¿…é¡»ç”¨: from diffuser.models.diffusion import ...

# try:
#     from diffuser.models.diffusion import GaussianDiffusion 
#     from diffuser.utils.training import Trainer 
# except ImportError as e:
#     print("\nâŒ å¯¼å…¥å¤±è´¥ï¼è¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„æ˜¯å¦å¦‚ä¸‹ï¼š")
#     print(f"   {project_root}/diffuser/models/diffusion.py (åŸ diffusionåˆå§‹ç‰ˆæœ¬.py)")
#     print(f"   {project_root}/diffuser/utils/training.py")
#     print(f"æŠ¥é”™ä¿¡æ¯: {e}")
#     sys.exit(1)

# # ä¸€ä¸ªç®€å•çš„ Dummy Renderer
# class DummyRenderer:
#     def composite(self, savepath, observations):
#         pass 

# def main():
#     # ================= é…ç½® =================
#     dataset_name = 'dataset_raw.npz' # æ ¹æ®éœ€è¦ä¿®æ”¹: 'dataset_truncated.npz' æˆ– 'dataset_safe_only.npz'
#     dataset_path = os.path.join(project_root, 'datasets', dataset_name)
#     save_dir = os.path.join(project_root, 'diffuser_checkpoints', dataset_name.replace(".npz", ""))
#     os.makedirs(save_dir, exist_ok=True)
#     device = 'cuda:0'
#     horizon = 64
#     n_diffusion_steps = 100 # è®ºæ–‡é€šå¸¸ç”¨ 20 æˆ– 100ï¼Œè®­ç»ƒå¯ä»¥å…ˆè®¾å°ä¸€ç‚¹è·‘é€šæµç¨‹
#     batch_size = 256
#     n_train_steps = 100000
    
#     # ================= 1. åŠ è½½æ•°æ® =================
#     if not os.path.exists(dataset_path):
#         raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®é›†: {dataset_path}\nè¯·å…ˆè¿è¡Œ 1_preprocess_data.py ç”Ÿæˆæ•°æ®ï¼")

#     dataset = SafetyGymDataset(dataset_path, horizon=horizon)
#     renderer = DummyRenderer()
    
#     print(f"Observation Dim: 26")
#     print(f"Action Dim: 2")
    
#     # ================= 2. æ„å»ºæ¨¡å‹ (Temporal U-Net) =================
#     from diffuser.models.temporal import TemporalUnet 
    
#     model = TemporalUnet(
#         horizon=horizon,
#         transition_dim=26 + 2, # obs + act
#         cond_dim=26,
#         dim=256,
#         dim_mults=(1, 2, 4)
#     ).to(device)
    
#     # ================= 3. æ„å»º Diffuser =================
#     diffusion = GaussianDiffusion(
#         model=model,
#         horizon=horizon,
#         observation_dim=26,
#         action_dim=2,
#         n_timesteps=n_diffusion_steps,
#         loss_type='l2',
#         clip_denoised=True,
#         predict_epsilon=False, 
#         action_weight=10.0,   
#     ).to(device)
    
#     # æ³¨å…¥ normalizer (Trainer éœ€è¦ç”¨åˆ°)
#     diffusion.normalizer = dataset 
    
#     # ================= 4. å¼€å§‹è®­ç»ƒ =================
#     trainer = Trainer(
#         diffusion_model=diffusion,
#         dataset=dataset,
#         renderer=renderer,
#         train_batch_size=batch_size,
#         train_lr=2e-5,
#         results_folder=save_dir,
#         save_freq=1000,
#         label_freq=1000,
#         log_freq=100,
#     )
    
#     print(f"=== å¼€å§‹è®­ç»ƒ: {dataset_name} ===")
#     trainer.train(n_train_steps)

# if __name__ == '__main__':
#     main()

import torch
import numpy as np
import os
import sys
import argparse  # ğŸ”¥ã€æ–°å¢ã€‘å¼•å…¥å‚æ•°è§£æåº“

# =================================================================
# 1. è·¯å¾„è®¾ç½®
# =================================================================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)

if project_root not in sys.path:
    sys.path.append(project_root)

print(f"âœ… å·²æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„: {project_root}")
sys.path.append(current_dir)

try:
    from dataset_adapter import SafetyGymDataset
except ImportError:
    print("âš ï¸ åœ¨å½“å‰ç›®å½•ä¸‹æ‰¾ä¸åˆ° dataset_adapterï¼Œå°è¯•ä»ä¸Šä¸€çº§æŸ¥æ‰¾...")
    from scripts.dataset_adapter import SafetyGymDataset

# =================================================================
# 2. å¯¼å…¥ Diffuser æ¨¡å—
# =================================================================
try:
    from diffuser.models.diffusion import GaussianDiffusion
    from diffuser.utils.training import Trainer
    from diffuser.models.temporal import TemporalUnet
except ImportError as e:
    print("\nâŒ å¯¼å…¥å¤±è´¥ï¼è¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„ã€‚")
    print(f"æŠ¥é”™ä¿¡æ¯: {e}")
    sys.exit(1)

class DummyRenderer:
    def composite(self, savepath, observations):
        pass

def main():
    # ================= ğŸ”¥ã€ä¿®æ”¹ã€‘å‚æ•°è§£æ =================
    parser = argparse.ArgumentParser()
    
    # 1. æ•°æ®é›†åç§° (é»˜è®¤æŒ‡å‘ v2_raw)
    parser.add_argument('--dataset', type=str, default='dataset_v2_raw.npz', 
                        help='dataset file name in ./datasets/')
    
    # 2. æ¨¡å‹ä¿å­˜è·¯å¾„ (å…è®¸è‡ªå®šä¹‰ï¼Œä¸å†å†™æ­»)
    parser.add_argument('--save_path', type=str, default='./diffuser_checkpoints/default_run',
                        help='path to save checkpoints')
    
    # 3. ç›®æ ‡æƒé‡ (é»˜è®¤ 1.0ï¼Œæƒ³åŠ å¼º Goal ä¿¡å·å°±è®¾å¤§ï¼Œæ¯”å¦‚ 5.0 æˆ– 10.0)
    parser.add_argument('--goal_weight', type=float, default=1.0, 
                        help='multiply goal signal by this weight')
    
    # å…¶ä»–è®­ç»ƒå‚æ•°
    parser.add_argument('--n_train_steps', type=int, default=100000)
    parser.add_argument('--batch_size', type=int, default=256)
    
    args = parser.parse_args()

    # ================= é…ç½®è·¯å¾„ =================
    dataset_path = os.path.join(project_root, 'datasets', args.dataset)
    save_dir = args.save_path  # ğŸ”¥ ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„è·¯å¾„
    
    os.makedirs(save_dir, exist_ok=True)
    
    device = 'cuda:0'
    horizon = 64
    n_diffusion_steps = 100 

    # ================= 1. åŠ è½½æ•°æ® =================
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®é›†: {dataset_path}\nè¯·ç¡®ä¿æ•°æ®åœ¨ datasets æ–‡ä»¶å¤¹ä¸‹ï¼")

    print(f"Loading Dataset: {args.dataset}")
    print(f"Goal Weight: {args.goal_weight}x")
    
    # ğŸ”¥ã€ä¿®æ”¹ã€‘ä¼ å…¥ goal_weight å‚æ•°
    # æ³¨æ„ï¼šè¿™éœ€è¦ä½ çš„ dataset_adapter.py __init__ å·²ç»æ”¯æŒ goal_weight å‚æ•°
    dataset = SafetyGymDataset(
        dataset_path, 
        horizon=horizon, 
        goal_weight=args.goal_weight 
    )
    
    renderer = DummyRenderer()
    
    print(f"Observation Dim: 26")
    print(f"Action Dim: 2")
    
    # ================= 2. æ„å»ºæ¨¡å‹ =================
    model = TemporalUnet(
        horizon=horizon,
        transition_dim=26 + 2,
        cond_dim=26,
        dim=256,
        dim_mults=(1, 2, 4)
    ).to(device)
    
    # ================= 3. æ„å»º Diffuser =================
    diffusion = GaussianDiffusion(
        model=model,
        horizon=horizon,
        observation_dim=26,
        action_dim=2,
        n_timesteps=n_diffusion_steps,
        loss_type='l2',
        clip_denoised=True,
        predict_epsilon=False, # åšæŒä½¿ç”¨ False (Predict X_Start)
        action_weight=10.0,   
    ).to(device)
    
    diffusion.normalizer = dataset
    
    # ================= 4. å¼€å§‹è®­ç»ƒ =================
    trainer = Trainer(
        diffusion_model=diffusion,
        dataset=dataset,
        renderer=renderer,
        train_batch_size=args.batch_size,
        train_lr=2e-5,
        
        # ğŸ”¥ã€ä¿®æ”¹ã€‘ç»“æœä¿å­˜è·¯å¾„
        results_folder=save_dir,
        
        save_freq=1000,
        label_freq=1000,
        log_freq=100,
    )
    
    print(f"=== å¼€å§‹è®­ç»ƒ ===")
    print(f"   Dataset: {args.dataset}")
    print(f"   Save Path: {save_dir}")
    print(f"   Goal Weight: {args.goal_weight}")
    
    trainer.train(args.n_train_steps)

if __name__ == '__main__':
    main()