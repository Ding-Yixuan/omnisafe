import torch
import torch.nn as nn
import numpy as np
import os
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import gymnasium
import safety_gymnasium
# å¼•å…¥ä½ çš„ç¯å¢ƒ Patchï¼Œç”¨äº Evaluation
from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0
from safety_gymnasium.assets.geoms import Hazards

# =================================================================
# 1. ç¯å¢ƒ Patch (å¿…é¡»ä¸é‡‡é›†æ—¶ä¸€è‡´)
# =================================================================
def patched_init(self, config):
    self.lidar_num_bins = 16
    self.lidar_max_dist = 3.0
    self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
    self.task_name = 'GoalLevel1_Reproduction'
    config.update({'lidar_num_bins': 16, 'lidar_max_dist': 3.0, 
                   'sensors_obs': self.sensors_obs, 'task_name': self.task_name})
    GoalLevel0.__init__(self, config=config)
    self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
    self._add_geoms(Hazards(num=2, keepout=0.2)) # 0.2

def patched_obs(self):
    lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group) 
    acc = self.agent.get_sensor('accelerometer')[:2]
    vel = self.agent.get_sensor('velocimeter')[:2]
    gyro = self.agent.get_sensor('gyro')[-1:]
    mag = self.agent.get_sensor('magnetometer')[:2]
    sensor_vec = np.concatenate([acc, vel, gyro, mag])
    vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
    x, y = vec[0], vec[1]
    z = x + 1j * y
    dist = np.exp(-np.abs(z)) 
    angle = np.angle(z)
    goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])
    return np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)

GoalLevel1.__init__ = patched_init
GoalLevel1.obs = patched_obs

# =================================================================
# 2. é…ç½®å‚æ•°
# =================================================================
CONFIG = {
    'dataset_path': './data_pro/ppolag_xinde8ge.npz', # ğŸ‘ˆ ç¡®ä¿è·¯å¾„å¯¹
    'horizon': 64,
    'obs_dim': 26,
    'act_dim': 2,
    'hidden_dim': 256,
    'train_steps': 100000,
    'batch_size': 256,
    'lr': 2e-4,
    'device': 'cuda:0',
    'save_dir': './diffuser_checkpoints/best_auto_save', # ğŸ‘ˆ æ–°è·¯å¾„
    'eval_freq': 5000,      # æ¯ 5000 æ­¥è¯„ä¼°ä¸€æ¬¡
    'eval_episodes': 10,    # æ¯æ¬¡è¯„ä¼°è·‘ 10 ä¸ªå›åˆ
}

# =================================================================
# 3. æ•°æ®é›†ä¸ç½‘ç»œ (ä¿æŒä¸å˜)
# =================================================================
class TrajectoryDataset(Dataset):
    def __init__(self, data_path, horizon=64):
        print(f"ğŸ“‚ Loading data from {data_path}...")
        raw_data = np.load(data_path)
        self.obs = raw_data['obs'].astype(np.float32)
        self.act = raw_data['act'].astype(np.float32)
        # å…¼å®¹ segment_id æˆ– episode_done
        if 'segment_id' in raw_data:
            self.segment_ids = raw_data['segment_id']
        else:
            # ç®€å•çš„å¤‡é€‰æ–¹æ¡ˆï¼šå¦‚æœæ²¡æœ‰ segment_idï¼Œå‡è®¾åªæœ‰ä¸€æ¡é•¿è½¨è¿¹ (ä¸æ¨è)
            self.segment_ids = np.zeros(len(self.obs))
            
        self.mins = np.concatenate([self.obs.min(axis=0), self.act.min(axis=0)])
        self.maxs = np.concatenate([self.obs.max(axis=0), self.act.max(axis=0)])
        self.maxs[self.maxs == self.mins] += 1.0 # é˜²é™¤é›¶

        self.indices = []
        total_steps = len(self.obs)
        print("âœ‚ï¸  Slicing trajectories...")
        for i in range(total_steps - horizon + 1):
            if self.segment_ids[i] == self.segment_ids[i + horizon - 1]:
                self.indices.append(i)
        print(f"âœ… Created {len(self.indices)} sequences.")
        
    def normalize(self, x):
        x_norm = (x - self.mins) / (self.maxs - self.mins)
        return 2 * x_norm - 1

    def unnormalize(self, x):
        x_01 = (x + 1) / 2
        return x_01 * (self.maxs - self.mins) + self.mins
        
    def __len__(self): return len(self.indices)
    def __getitem__(self, idx):
        start = self.indices[idx]
        end = start + CONFIG['horizon']
        traj = np.concatenate([self.obs[start:end], self.act[start:end]], axis=-1)
        return torch.tensor(self.normalize(traj), dtype=torch.float32)

# --- U-Net Components ---
class SinusoidalPosEmb(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim
    def forward(self, x):
        device = x.device
        half_dim = self.dim // 2
        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)
        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)
        emb = x[:, None] * emb[None, :]
        return torch.cat((emb.sin(), emb.cos()), dim=-1)

class TemporalUnet(nn.Module):
    def __init__(self, transition_dim, dim=128):
        super().__init__()
        self.time_mlp = nn.Sequential(
            SinusoidalPosEmb(dim), nn.Linear(dim, dim * 4), nn.Mish(), nn.Linear(dim * 4, dim),
        )
        self.down1 = nn.Sequential(nn.Conv1d(transition_dim, dim, 3, padding=1), nn.Mish())
        self.down2 = nn.Sequential(nn.Conv1d(dim, dim * 2, 3, padding=1), nn.Mish())
        self.down3 = nn.Sequential(nn.Conv1d(dim * 2, dim * 4, 3, padding=1), nn.Mish())
        self.up1 = nn.Sequential(nn.Conv1d(dim * 4, dim * 2, 3, padding=1), nn.Mish())
        self.up2 = nn.Sequential(nn.Conv1d(dim * 2, dim, 3, padding=1), nn.Mish())
        self.final_conv = nn.Conv1d(dim, transition_dim, 1)

    def forward(self, x, t):
        t_emb = self.time_mlp(t).unsqueeze(-1)
        x1 = self.down1(x) + t_emb
        x2 = self.down2(x1)
        x3 = self.down3(x2)
        x = self.up1(x3) + x2
        x = self.up2(x) + x1
        return self.final_conv(x)

# --- Diffusion Manager ---
class GaussianDiffusion(nn.Module):
    def __init__(self, model, horizon, transition_dim, n_timesteps=100): # ğŸ‘ˆ 100æ­¥æ¨ç†å¤Ÿå¿«äº†
        super().__init__()
        self.model = model
        self.horizon = horizon
        self.transition_dim = transition_dim
        self.n_timesteps = n_timesteps
        betas = torch.linspace(1e-4, 2e-2, n_timesteps)
        alphas = 1. - betas
        alphas_cumprod = torch.cumprod(alphas, dim=0)
        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))
        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))
        self.register_buffer('betas', betas)
        self.register_buffer('sqrt_recip_alphas', torch.sqrt(1. / alphas))
        self.register_buffer('posterior_variance', betas * (1. - torch.cat([torch.tensor([1.]), alphas_cumprod[:-1]])) / (1. - alphas_cumprod))

    def compute_loss(self, x_0):
        batch_size = x_0.shape[0]
        t = torch.randint(0, self.n_timesteps, (batch_size,), device=x_0.device).long()
        noise = torch.randn_like(x_0)
        coef1 = self.sqrt_alphas_cumprod[t].reshape(-1, 1, 1)
        coef2 = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1, 1)
        x_t = coef1 * x_0 + coef2 * noise
        noise_pred = self.model(x_t.permute(0, 2, 1), t).permute(0, 2, 1)
        return nn.functional.mse_loss(noise_pred, noise)

    @torch.no_grad()
    def sample(self, cond_obs):
        """ ç®€å•çš„é‡‡æ ·é€»è¾‘ï¼Œç”¨äº Eval """
        batch_size = cond_obs.shape[0]
        device = cond_obs.device
        
        # ä»çº¯å™ªå£°å¼€å§‹
        # Shape: [Batch, Horizon, Dim]
        x = torch.randn((batch_size, self.horizon, self.transition_dim), device=device)
        
        # DDPM é€†å‘é‡‡æ ·
        for i in reversed(range(self.n_timesteps)):
            t = torch.full((batch_size,), i, device=device, dtype=torch.long)
            
            # é¢„æµ‹å™ªå£°
            noise_pred = self.model(x.permute(0, 2, 1), t).permute(0, 2, 1)
            
            # è®¡ç®— x_{t-1}
            # mean = 1/sqrt(alpha) * (x_t - beta/sqrt(1-alpha_bar) * noise_pred)
            alpha_t = self.sqrt_recip_alphas[i] ** (-2) # recover alpha from sqrt_recip
            # è¿™é‡Œç®€åŒ–å…¬å¼ï¼Œç›´æ¥ç”¨ standard DDPM update
            beta_t = self.betas[i]
            sqrt_one_minus_alpha_cumprod_t = self.sqrt_one_minus_alphas_cumprod[i]
            sqrt_recip_alpha_t = self.sqrt_recip_alphas[i]
            
            mean = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alpha_cumprod_t * noise_pred)
            
            if i > 0:
                noise = torch.randn_like(x)
                sigma = torch.sqrt(self.posterior_variance[i])
                x = mean + sigma * noise
            else:
                x = mean
                
            # ã€é‡è¦ã€‘æ¯æ¬¡å»å™ªåï¼Œå¼ºåˆ¶æŠŠç¬¬ä¸€æ­¥çš„ Observation è®¾ä¸ºå½“å‰çš„çœŸå® Obs
            # è¿™å« "In-painting" æŠ€å·§ï¼Œä¿è¯è§„åˆ’ä»å½“å‰çŠ¶æ€å¼€å§‹
            # x[:, 0, :26] = cond_obs # è¿™é‡Œéœ€è¦ normalized obs
            # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬åœ¨ loss é‡Œä¸ mask obsï¼Œä½†åœ¨é‡‡æ ·æ—¶å¹¶ä¸å¼ºåˆ¶æ›¿æ¢ (Open-loop planning)
            # æˆ–è€…æˆ‘ä»¬åœ¨ unnormalize ååªå–ç¬¬ä¸€ä¸ª Action
            
        return x

# =================================================================
# 4. è¯„ä¼°å‡½æ•° (Evaluation) - è‡ªåŠ¨æ‰“åˆ†
# =================================================================
# =================================================================
# 4. è¯„ä¼°å‡½æ•° (Evaluation) - è‡ªåŠ¨æ‰“åˆ† [ä¿®å¤ç‰ˆ]
# =================================================================
def evaluate(diffusion_model, dataset, eval_episodes=10):
    """ 
    åœ¨çœŸå®ç¯å¢ƒä¸­è·‘ N ä¸ªå›åˆã€‚
    ç­–ç•¥ï¼šæ¯ä¸€æ­¥è°ƒç”¨ Diffuser ç”Ÿæˆä¸€æ¡è½¨è¿¹ï¼Œæ‰§è¡Œç¬¬ä¸€ä¸ªåŠ¨ä½œã€‚
    """
    # ã€ä¿®å¤1ã€‘ï¼šåŠ ä¸Š disable_env_checker=Trueï¼Œé˜²æ­¢ Gym æŠ¥é”™è¯´è¿”å›å€¼æ•°é‡ä¸å¯¹
    env = gymnasium.make('SafetyPointGoal1-v0', disable_env_checker=True).unwrapped
    device = CONFIG['device']
    
    total_collisions = 0
    total_success = 0
    total_reward = 0
    
    # å½’ä¸€åŒ–å‚æ•°
    mins = torch.tensor(dataset.mins, device=device)
    maxs = torch.tensor(dataset.maxs, device=device)
    
    print(f"\nğŸ§ª Evaluating (Episodes={eval_episodes})...")
    
    # ä¸´æ—¶è®¾ç½®ä¸º eval æ¨¡å¼
    diffusion_model.model.eval()
    
    for ep in range(eval_episodes):
        obs, _ = env.reset()
        done = False
        step = 0
        
        while not done and step < 200: 
            # (1) éšæœºåˆå§‹åŒ– x
            x = torch.randn((1, CONFIG['horizon'], CONFIG['obs_dim'] + CONFIG['act_dim']), device=device)
            
            # (2) å½’ä¸€åŒ–å½“å‰ Obs
            curr_obs_norm = (obs - dataset.mins[:26]) / (dataset.maxs[:26] - dataset.mins[:26])
            curr_obs_norm = 2 * curr_obs_norm - 1
            curr_obs_torch = torch.tensor(curr_obs_norm, device=device, dtype=torch.float32)
            
            # (3) é€†å‘å»å™ª
            with torch.no_grad():
                for i in reversed(range(diffusion_model.n_timesteps)):
                    t = torch.full((1,), i, device=device, dtype=torch.long)
                    
                    # In-painting: å¼ºåˆ¶ä¿®æ­£ç¬¬ 0 æ­¥çš„ Obs ä¸ºå½“å‰çœŸå® Obs
                    x[:, 0, :26] = curr_obs_torch 
                    
                    noise_pred = diffusion_model.model(x.permute(0, 2, 1), t).permute(0, 2, 1)
                    
                    beta_t = diffusion_model.betas[i]
                    sqrt_one_minus_alpha_cumprod_t = diffusion_model.sqrt_one_minus_alphas_cumprod[i]
                    sqrt_recip_alpha_t = diffusion_model.sqrt_recip_alphas[i]
                    
                    mean = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alpha_cumprod_t * noise_pred)
                    
                    if i > 0:
                        x = mean + torch.sqrt(diffusion_model.posterior_variance[i]) * torch.randn_like(x)
                    else:
                        x = mean
                
            # (4) é‡‡æ ·ç»“æŸï¼Œåå½’ä¸€åŒ–
            # åŠ äº† .detach() é˜²æ­¢æŠ¥é”™
            traj = x[0].detach().cpu().numpy() # [H, 28]
            traj = (traj + 1) / 2 * (dataset.maxs - dataset.mins) + dataset.mins
            
            # å–å‡ºç¬¬ä¸€ä¸ªåŠ¨ä½œ
            action = traj[0, 26:] 
            
            # ã€ä¿®å¤2ã€‘ï¼šå…¼å®¹ 5 æˆ– 6 ä¸ªè¿”å›å€¼çš„è§£åŒ…é€»è¾‘
            step_result = env.step(action)
            
            if len(step_result) == 6:
                # Safety Gym æ ‡å‡†: obs, reward, cost, terminated, truncated, info
                obs, reward, cost, terminated, truncated, info = step_result
                done = terminated or truncated
            elif len(step_result) == 5:
                # Standard Gym: obs, reward, terminated, truncated, info
                obs, reward, terminated, truncated, info = step_result
                cost = info.get('cost', 0.0) # å°è¯•ä» info æ‹¿ cost
                done = terminated or truncated
            else:
                raise ValueError(f"Env step returned {len(step_result)} values, expected 5 or 6.")
            
            # ç»Ÿè®¡
            if cost > 0: total_collisions += 1
            
            total_reward += reward
            step += 1
            
    # æ¢å¤è®­ç»ƒæ¨¡å¼
    diffusion_model.model.train()
            
    avg_collision = total_collisions / eval_episodes
    avg_reward = total_reward / eval_episodes
    
    # æ‰“åˆ†å…¬å¼
    score = avg_reward - 10 * avg_collision
    
    print(f"ğŸ“Š Eval Result: Reward={avg_reward:.2f}, Collisions={avg_collision:.2f} | Score={score:.2f}")
    return score
# =================================================================
# 5. ä¸»è®­ç»ƒå¾ªç¯
# =================================================================
def train():
    os.makedirs(CONFIG['save_dir'], exist_ok=True)
    device = torch.device(CONFIG['device'])
    
    # 1. å‡†å¤‡æ•°æ®
    dataset = TrajectoryDataset(CONFIG['dataset_path'], horizon=CONFIG['horizon'])
    dataloader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4)
    np.savez(os.path.join(CONFIG['save_dir'], 'normalization.npz'), mins=dataset.mins, maxs=dataset.maxs)

    # 2. åˆå§‹åŒ–æ¨¡å‹
    transition_dim = CONFIG['obs_dim'] + CONFIG['act_dim']
    unet = TemporalUnet(transition_dim=transition_dim, dim=CONFIG['hidden_dim']).to(device)
    # æ³¨æ„ï¼šè®­ç»ƒæ—¶ Timesteps å¯ä»¥å¤§ä¸€ç‚¹ (100)ï¼Œæ¨ç†æ—¶å†å†³å®š
    diffusion = GaussianDiffusion(unet, CONFIG['horizon'], transition_dim, n_timesteps=100).to(device)
    
    optimizer = torch.optim.Adam(unet.parameters(), lr=CONFIG['lr'])
    
    best_score = -float('inf') # åˆå§‹æœ€ä½åˆ†
    
    print(f"ğŸš€ Start Training... Steps: {CONFIG['train_steps']}")
    
    step = 0
    while step < CONFIG['train_steps']:
        for batch_traj in dataloader:
            batch_traj = batch_traj.to(device)
            loss = diffusion.compute_loss(batch_traj)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            step += 1
            if step % 100 == 0:
                print(f"Step {step} | Loss: {loss.item():.6f}")

            # --- æ ¸å¿ƒï¼šå®šæœŸè¯„ä¼°å¹¶ä¿å­˜æœ€ä½³ ---
            if step % CONFIG['eval_freq'] == 0:
                # è¯„ä¼°
                current_score = evaluate(diffusion, dataset, eval_episodes=CONFIG['eval_episodes'])
                
                # è®°å½• Best
                if current_score > best_score:
                    best_score = current_score
                    save_path = os.path.join(CONFIG['save_dir'], 'best_model.pt')
                    torch.save(unet.state_dict(), save_path)
                    print(f"ğŸŒŸ New Best Model Found! Score: {best_score:.2f} -> Saved to {save_path}")
                else:
                    print(f"   (Current Score {current_score:.2f} < Best {best_score:.2f}, skip save)")
            
            if step >= CONFIG['train_steps']: break

    print("ğŸ‰ Training Finished!")

if __name__ == '__main__':
    train()