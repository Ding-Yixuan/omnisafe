# import os
# import torch
# import numpy as np
# import omnisafe
# import safety_gymnasium
# import gymnasium
# from safety_gymnasium.assets.geoms import Hazards
# # å¼•å…¥åŸå§‹ç±»
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0

# # =================================================================
# # 1. ã€æ ¸å¿ƒå¿…é¡»ã€‘æ¤å…¥ Monkey Patch
# # =================================================================

# def patched_init(self, config):
#     """æ›¿æ¢ GoalLevel1.__init__"""
#     self.lidar_num_bins = 16
#     self.lidar_max_dist = 3.0
#     self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
#     self.task_name = 'GoalLevel1_Reproduction'
    
#     config.update({
#         'lidar_num_bins': 16,
#         'lidar_max_dist': 3.0,
#         'sensors_obs': self.sensors_obs,
#         'task_name': self.task_name
#     })
    
#     GoalLevel0.__init__(self, config=config)
    
#     # ä¿®æ”¹ç¯å¢ƒ: 2 Hazards
#     self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
#     self._add_geoms(Hazards(num=2, keepout=0.18))
#     print("ã€Patchã€‘ç¯å¢ƒåœ°å›¾å·²ä¿®æ”¹: 2 Hazards")

# def patched_build_observation_space(self):
#     """æ›¿æ¢ build_observation_space"""
#     self.observation_space = gymnasium.spaces.Box(
#         low=-np.inf, high=np.inf, shape=(26,), dtype=np.float32
#     )

# def patched_obs(self):
#     """æ›¿æ¢ obs æ–¹æ³• (ç¡®ä¿ 26 ç»´)"""
#     # 1. Hazard Lidar (16ç»´)
#     lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group) 
    
#     # 2. Sensors (7ç»´)
#     acc = self.agent.get_sensor('accelerometer')[:2]
#     vel = self.agent.get_sensor('velocimeter')[:2]
#     gyro = self.agent.get_sensor('gyro')[-1:]
#     mag = self.agent.get_sensor('magnetometer')[:2]
#     sensor_vec = np.concatenate([acc, vel, gyro, mag])

#     # 3. Goal (3ç»´)
#     vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
#     x, y = vec[0], vec[1]
#     z = x + 1j * y
#     dist = np.abs(z)
#     dist = np.exp(-dist) 
#     angle = np.angle(z)
#     goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])

#     # 4. æ‹¼æ¥
#     flat_obs = np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)
#     return flat_obs

# # åº”ç”¨è¡¥ä¸
# GoalLevel1.__init__ = patched_init
# GoalLevel1.build_observation_space = patched_build_observation_space
# GoalLevel1.obs = patched_obs
# print("âœ… æˆåŠŸåº”ç”¨ç¯å¢ƒ Monkey Patch (26ç»´æ¨¡å¼)")

# # =================================================================
# # 2. é…ç½®éƒ¨åˆ†
# # =================================================================
# # âš ï¸ è¯·ç¡®è®¤æ­¤è·¯å¾„æ˜¯æ­£ç¡®çš„æ¨¡å‹è·¯å¾„
# LOG_DIR = './runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2026-02-07-19-09-38'

# SAVE_NAME = 'safety_gym_26dim_data.npz'
# NUM_SAMPLES = 50000 
# ENV_ID = 'SafetyPointGoal1-v0'

# # =================================================================
# # 3. è¾…åŠ©å‡½æ•°
# # =================================================================
# def find_actor(obj, depth=0):
#     """é€’å½’æœç´¢ Actor (ç­–ç•¥ç½‘ç»œ)"""
#     if depth > 4: return None
#     if hasattr(obj, 'predict') and callable(getattr(obj, 'predict')):
#         if not isinstance(obj, omnisafe.Evaluator):
#             return obj
#     for attr_name in dir(obj):
#         if attr_name.startswith('__'): continue
#         try:
#             attr_obj = getattr(obj, attr_name)
#             res = find_actor(attr_obj, depth + 1)
#             if res: return res
#         except:
#             continue
#     return None

# def convert_to_numpy(data):
#     """ã€æ ¸å¿ƒä¿®å¤ã€‘é€šç”¨è½¬æ¢å‡½æ•°ï¼šå¤„ç† Tensorã€Deviceã€ç»´åº¦"""
#     # å¦‚æœæ˜¯ Tensorï¼Œå…ˆè½¬ CPU å†è½¬ Numpy
#     if isinstance(data, torch.Tensor):
#         data = data.detach().cpu().numpy()
    
#     # å¦‚æœæ˜¯ numpy æ•°ç»„
#     if isinstance(data, np.ndarray):
#         # å¤„ç† batch ç»´åº¦ (1, N) -> (N,)
#         if data.ndim > 1 and data.shape[0] == 1:
#             data = data.squeeze(0)
#         # å¦‚æœæ˜¯ 0 ç»´æ•°ç»„ (scalar)ï¼Œè½¬ä¸º python scalar
#         if data.ndim == 0:
#             data = data.item()
            
#     return data

# def clean_data_dict(dataset):
#     """æœ€ç»ˆæ¸…ç†ï¼Œå°† list å †å ä¸ºå¤§ numpy array"""
#     cleaned_data = {}
#     for k, v in dataset.items():
#         # è¿™é‡Œå‡è®¾ v ä¸­çš„å…ƒç´ å·²ç»æ˜¯å¤„ç†å¥½çš„ numpy array æˆ– scalar
#         arr = np.array(v)
        
#         if k in ['terminals', 'timeouts']:
#             arr = arr.astype(np.bool_)
#         else:
#             arr = arr.astype(np.float32)
            
#         cleaned_data[k] = arr
#     return cleaned_data

# if __name__ == '__main__':
#     # =================================================================
#     # 4. åŠ è½½æ¨¡å‹ä¸ç¯å¢ƒ
#     # =================================================================
#     evaluator = omnisafe.Evaluator()
#     # è‡ªåŠ¨å°è¯•åŠ è½½æ¨¡å‹
#     model_files = ['model.pt', 'epoch-500.pt', 'epoch-10.pt']
#     loaded = False
#     for mf in model_files:
#         try:
#             evaluator.load_saved(save_dir=LOG_DIR, model_name=mf)
#             print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {mf}")
#             loaded = True
#             break
#         except Exception as e:
#             continue
    
#     if not loaded:
#         print(f"âŒ æ— æ³•åœ¨ {LOG_DIR} ä¸­æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_files}")
#         # å¦‚æœä½ éœ€è¦å¼ºè¡Œç»§ç»­ï¼ˆæ¯”å¦‚åªæœ‰ epoch-100.ptï¼‰ï¼Œè¯·æ‰‹åŠ¨ä¿®æ”¹ä¸Šé¢çš„åˆ—è¡¨æˆ–è¿™é‡Œ
#         # raise FileNotFoundError("Model file not found")

#     actor = find_actor(evaluator)
#     if actor is None:
#         raise RuntimeError("âŒ æ— æ³•æ‰¾åˆ° Actor ç½‘ç»œï¼Œè¯·æ£€æŸ¥æ¨¡å‹åŠ è½½è·¯å¾„ã€‚")
    
#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
#     actor.to(device)
#     actor.eval()
    
#     env = evaluator._env
#     print(f"å½“å‰ç¯å¢ƒè§‚æµ‹ç©ºé—´: {env.observation_space.shape}")
#     assert env.observation_space.shape == (26,), "âŒ ç¯å¢ƒç»´åº¦ä¾ç„¶ä¸å¯¹ï¼Patch æœªç”Ÿæ•ˆã€‚"

#     # =================================================================
#     # 5. é‡‡é›†å¾ªç¯
#     # =================================================================
#     dataset = {
#         'observations': [],
#         'actions': [],
#         'next_observations': [], 
#         'rewards': [],
#         'costs': [],             
#         'terminals': [],
#         'timeouts': []
#     }

#     obs, _ = env.reset()
#     episode_step = 0
#     collected_steps = 0

#     print(f"å¼€å§‹é‡‡é›† {NUM_SAMPLES} æ­¥æ•°æ®...")

#     while collected_steps < NUM_SAMPLES:
#         # æ¨¡å‹é¢„æµ‹
#         with torch.no_grad():
#             # ç¡®ä¿ obs æ˜¯ Tensor ä¸”åœ¨ device ä¸Š
#             obs_tensor = torch.as_tensor(obs, dtype=torch.float32).to(device)
#             if obs_tensor.ndim == 1:
#                 obs_tensor = obs_tensor.unsqueeze(0) # (1, 26)
            
#             act = actor.predict(obs_tensor, deterministic=False) 
            
#         act_cpu = act.squeeze(0).cpu()
        
#         # ç¯å¢ƒæ­¥è¿›
#         # æ³¨æ„ï¼šenv.step è¿”å›çš„ reward/cost å¯èƒ½æ˜¯ Tensor ä¹Ÿå¯èƒ½æ˜¯ float
#         next_obs, reward, cost, terminated, truncated, info = env.step(act_cpu)
        
#         # ã€å…³é”®ä¿®å¤ã€‘å­˜å…¥å‰ç«‹åˆ»è½¬ä¸º Numpy/Scalar
#         # é¿å…åç»­å‡ºç° "only one element tensors can be converted..." é”™è¯¯
#         safe_obs = convert_to_numpy(obs)
#         safe_act = convert_to_numpy(act_cpu)
#         safe_next_obs = convert_to_numpy(next_obs)
#         safe_reward = convert_to_numpy(reward)
#         safe_cost = convert_to_numpy(cost)
        
#         dataset['observations'].append(safe_obs)
#         dataset['actions'].append(safe_act)
#         dataset['next_observations'].append(safe_next_obs)
#         dataset['rewards'].append(safe_reward)
#         dataset['costs'].append(safe_cost)
#         dataset['terminals'].append(terminated)
#         dataset['timeouts'].append(truncated)
        
#         obs = next_obs
#         episode_step += 1
#         collected_steps += 1
        
#         if terminated or truncated:
#             obs, _ = env.reset()
#             episode_step = 0
            
#         if collected_steps % 5000 == 0:
#             print(f"è¿›åº¦: {collected_steps} / {NUM_SAMPLES}")

#     # =================================================================
#     # 6. ä¿å­˜æ•°æ®
#     # =================================================================
#     print("æ­£åœ¨å¤„ç†å¹¶ä¿å­˜æ•°æ®...")
#     final_data = clean_data_dict(dataset)
    
#     save_path = os.path.join(LOG_DIR, SAVE_NAME)
#     np.savez(save_path, **final_data)
    
#     print(f"âœ… æ•°æ®é‡‡é›†å®Œæˆï¼")
#     print(f"ä¿å­˜è·¯å¾„: {save_path}")
#     print(f"è§‚æµ‹ç»´åº¦: {final_data['observations'].shape}")
#     print(f"æˆæœ¬æ€»æ•°(Unsafe steps): {np.sum(final_data['costs'] > 0)}")



##########################2

# import os
# import torch
# import numpy as np
# import omnisafe
# import safety_gymnasium
# import gymnasium
# from safety_gymnasium.assets.geoms import Hazards
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0

# # =================================================================
# # 1. Monkey Patch (ç¡®ä¿å’Œä½ è®­ç»ƒPPOæ—¶çš„ç¯å¢ƒä¸€è‡´ï¼)
# # =================================================================
# # âš ï¸ é‡è¦æç¤ºï¼šå¦‚æœä½ çš„ PPO æ¨¡å‹æ˜¯åœ¨"é»˜è®¤ç¯å¢ƒ"ä¸‹è®­ç»ƒçš„ï¼Œ
# # è¯·æ³¨é‡Šæ‰ä¸‹é¢è¿™ä¸ª Patchï¼Œå¦åˆ™ PPO ä¼šå˜å‚»ï¼
# # å¦‚æœä½ çš„ PPO ç¡®å®æ˜¯åœ¨ 26ç»´ ç¯å¢ƒä¸‹è®­ç»ƒçš„ï¼Œè¯·ä¿ç•™ã€‚
# # =================================================================

# def patched_init(self, config):
#     self.lidar_num_bins = 16
#     self.lidar_max_dist = 3.0
#     self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
#     self.task_name = 'GoalLevel1_Reproduction'
#     config.update({
#         'lidar_num_bins': 16,
#         'lidar_max_dist': 3.0,
#         'sensors_obs': self.sensors_obs,
#         'task_name': self.task_name
#     })
#     GoalLevel0.__init__(self, config=config)
#     self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
#     self._add_geoms(Hazards(num=2, keepout=0.18))

# def patched_build_observation_space(self):
#     self.observation_space = gymnasium.spaces.Box(low=-np.inf, high=np.inf, shape=(26,), dtype=np.float32)

# def patched_obs(self):
#     lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group) 
#     acc = self.agent.get_sensor('accelerometer')[:2]
#     vel = self.agent.get_sensor('velocimeter')[:2]
#     gyro = self.agent.get_sensor('gyro')[-1:]
#     mag = self.agent.get_sensor('magnetometer')[:2]
#     sensor_vec = np.concatenate([acc, vel, gyro, mag])
#     vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
#     x, y = vec[0], vec[1]
#     z = x + 1j * y
#     dist = np.exp(-np.abs(z)) 
#     angle = np.angle(z)
#     goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])
#     return np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)

# GoalLevel1.__init__ = patched_init
# GoalLevel1.build_observation_space = patched_build_observation_space
# GoalLevel1.obs = patched_obs
# print("âœ… ç¯å¢ƒ Patch å·²åº”ç”¨ (26ç»´)")

# # =================================================================
# # 2. é…ç½®
# # =================================================================
# LOG_DIR = './runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2026-02-07-19-09-38'
# SAVE_NAME = 'safety_gym_26dim_data_v2.npz' # æ”¹ä¸ªåå­—ï¼Œv2
# NUM_SAMPLES = 200000  # ã€å¢åŠ æ•°æ®é‡ã€‘ åˆ° 20ä¸‡
# ENV_ID = 'SafetyPointGoal1-v0'

# # =================================================================
# # 3. è¾…åŠ©å‡½æ•°
# # =================================================================
# def find_actor(obj, depth=0):
#     if depth > 4: return None
#     if hasattr(obj, 'predict') and callable(getattr(obj, 'predict')):
#         if not isinstance(obj, omnisafe.Evaluator): return obj
#     for attr_name in dir(obj):
#         if attr_name.startswith('__'): continue
#         try:
#             attr_obj = getattr(obj, attr_name)
#             res = find_actor(attr_obj, depth + 1)
#             if res: return res
#         except: continue
#     return None

# def convert_to_numpy(data):
#     if isinstance(data, torch.Tensor):
#         data = data.detach().cpu().numpy()
#     if isinstance(data, np.ndarray):
#         if data.ndim > 1 and data.shape[0] == 1:
#             data = data.squeeze(0)
#         if data.ndim == 0:
#             data = data.item()
#     return data

# def clean_data_dict(dataset):
#     cleaned_data = {}
#     for k, v in dataset.items():
#         arr = np.array(v)
#         if k in ['terminals', 'timeouts']:
#             arr = arr.astype(np.bool_)
#         else:
#             arr = arr.astype(np.float32)
#         cleaned_data[k] = arr
#     return cleaned_data

# if __name__ == '__main__':
#     # åŠ è½½æ¨¡å‹
#     evaluator = omnisafe.Evaluator()
#     model_loaded = False
#     # ä¼˜å…ˆåŠ è½½è®­ç»ƒæœ€ä¹…çš„ epoch-500
#     for mf in ['epoch-500.pt', 'model.pt']:
#         try:
#             evaluator.load_saved(save_dir=LOG_DIR, model_name=mf)
#             print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {mf}")
#             model_loaded = True
#             break
#         except: continue
    
#     if not model_loaded:
#         raise FileNotFoundError(f"âŒ åœ¨ {LOG_DIR} æ²¡æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")

#     actor = find_actor(evaluator)
#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
#     actor.to(device)
#     actor.eval()
    
#     env = evaluator._env
#     print(f"å½“å‰ç¯å¢ƒ Obs Dim: {env.observation_space.shape}")

#     # æ•°æ®å®¹å™¨
#     dataset = {'observations': [], 'actions': [], 'next_observations': [], 
#                'rewards': [], 'costs': [], 'terminals': [], 'timeouts': []}

#     obs, _ = env.reset()
#     collected_steps = 0
    
#     # è¯Šæ–­å˜é‡
#     episode_reward = 0
#     success_count = 0
#     episode_count = 0

#     print(f"\nïš€ å¼€å§‹é‡‡é›† {NUM_SAMPLES} æ­¥æ•°æ®...")
#     print("âš ï¸  è¯·è§‚å¯Ÿä¸‹æ–¹çš„ [ä¸“å®¶è¯Šæ–­] è¾“å‡ºï¼Œç¡®ä¿ PPO æ­£å¸¸å·¥ä½œï¼")

#     while collected_steps < NUM_SAMPLES:
        
#         with torch.no_grad():
#             obs_tensor = torch.as_tensor(obs, dtype=torch.float32).to(device)
#             if obs_tensor.ndim == 1: obs_tensor = obs_tensor.unsqueeze(0)
            
#             # ã€æ”¹ä¸º Trueã€‘ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼Œé¿å…éšæœºå™ªå£°å¯¼è‡´ç”»åœ†
#             act = actor.predict(obs_tensor, deterministic=True)
            
#         act_cpu = act.squeeze(0).cpu()
        
#         next_obs, reward, cost, terminated, truncated, info = env.step(act_cpu)
#         if collected_steps % 100 == 0:
#             print(f"\nï” [è¯Šæ–­ Step {collected_steps}]")
#             print(f"   Obs (Raw?): {obs[:5]} ... (çœ‹æ•°å€¼å¤§å°)")
#             print(f"   Act (Output): {act_cpu.numpy()} ... (çœ‹æ˜¯ä¸æ˜¯å¡æ­»åœ¨è¾¹ç•Œæˆ–0)")
#             print(f"   Reward: {reward} | Cost: {cost}")
        
#         # å­˜å‚¨
#         dataset['observations'].append(convert_to_numpy(obs))
#         dataset['actions'].append(convert_to_numpy(act_cpu))
#         dataset['next_observations'].append(convert_to_numpy(next_obs))
#         dataset['rewards'].append(convert_to_numpy(reward))
#         dataset['costs'].append(convert_to_numpy(cost))
#         dataset['terminals'].append(terminated)
#         dataset['timeouts'].append(truncated)
        
#         obs = next_obs
#         collected_steps += 1
#         episode_reward += reward

#         if terminated or truncated:
#             # ç»Ÿè®¡æˆåŠŸç‡ (Goal ä»»åŠ¡ Reward > 0 é€šå¸¸æ„å‘³ç€é è¿‘ç›®æ ‡ï¼Œå…·ä½“çœ‹ Cost)
#             episode_count += 1
#             if cost == 0: # ç®€å•ç²—æš´åˆ¤æ–­ï¼šæ²¡æ­»å°±ç®—ä¸€æ¬¡å®Œæ•´å°è¯•
#                  pass 
            
#             obs, _ = env.reset()
#             episode_reward = 0
            
#         if collected_steps % 10000 == 0:
#             print(f"è¿›åº¦: {collected_steps} / {NUM_SAMPLES} | å½“å‰ Episode Reward: {episode_reward:.2f}")

#     # ä¿å­˜
#     print("\nï’¾ æ­£åœ¨ä¿å­˜...")
#     final_data = clean_data_dict(dataset)
#     save_path = os.path.join(LOG_DIR, SAVE_NAME)
#     np.savez(save_path, **final_data)
    
#     # ï“Š æœ€ç»ˆè¯Šæ–­æŠ¥å‘Š
#     total_cost = np.sum(final_data['costs'])
#     print(f"="*40)
#     print(f"âœ… é‡‡é›†å®Œæˆ: {save_path}")
#     print(f"ï“Š æ•°æ®é›†ä½“æ£€æŠ¥å‘Š:")
#     print(f"   - æ€»æ­¥æ•°: {len(final_data['observations'])}")
#     print(f"   - å‘ç”Ÿç¢°æ’çš„æ€»æ­¥æ•° (Total Cost): {total_cost}")
#     print(f"   - åŠ¨ä½œå‡å€¼: {np.mean(final_data['actions'], axis=0)}")
#     print(f"   - åŠ¨ä½œæ–¹å·®: {np.std(final_data['actions'], axis=0)}")
#     print(f"="*40)
    
#     if np.std(final_data['actions']) < 0.05:
#         print("âš ï¸ ä¸¥é‡è­¦å‘Šï¼šé‡‡é›†åˆ°çš„åŠ¨ä½œæ–¹å·®æä½ï¼PPO è€å¸ˆå¯èƒ½åœ¨â€˜è£…æ­»â€™æˆ–â€˜ç”»åœ†â€™ã€‚")
#         print("   åŸå› å¯èƒ½æ˜¯ï¼šè®­ç»ƒæ—¶çš„ç¯å¢ƒ(60ç»´)å’Œé‡‡é›†æ—¶çš„ç¯å¢ƒ(Patch 26ç»´)ä¸åŒ¹é…ï¼")




# import os
# import torch
# import numpy as np
# import omnisafe
# import safety_gymnasium
# import gymnasium
# from safety_gymnasium.assets.geoms import Hazards
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0

# # =================================================================
# # 1. Monkey Patch (ä¿æŒä¸å˜)
# # =================================================================
# def patched_init(self, config):
#     self.lidar_num_bins = 16
#     self.lidar_max_dist = 3.0
#     self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
#     self.task_name = 'GoalLevel1_Reproduction'
#     config.update({'lidar_num_bins': 16, 'lidar_max_dist': 3.0, 'sensors_obs': self.sensors_obs, 'task_name': self.task_name})
#     GoalLevel0.__init__(self, config=config)
#     self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
#     self._add_geoms(Hazards(num=2, keepout=0.18))

# def patched_build_observation_space(self):
#     self.observation_space = gymnasium.spaces.Box(low=-np.inf, high=np.inf, shape=(26,), dtype=np.float32)

# def patched_obs(self):
#     # è¿™æ˜¯ç”Ÿæˆ Raw Obs çš„æ ¸å¿ƒå‡½æ•°
#     lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group) 
#     acc = self.agent.get_sensor('accelerometer')[:2]
#     vel = self.agent.get_sensor('velocimeter')[:2]
#     gyro = self.agent.get_sensor('gyro')[-1:]
#     mag = self.agent.get_sensor('magnetometer')[:2]
#     sensor_vec = np.concatenate([acc, vel, gyro, mag])
#     vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
#     x, y = vec[0], vec[1]
#     z = x + 1j * y
#     dist = np.exp(-np.abs(z)) 
#     angle = np.angle(z)
#     goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])
#     return np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)

# GoalLevel1.__init__ = patched_init
# GoalLevel1.build_observation_space = patched_build_observation_space
# GoalLevel1.obs = patched_obs
# print("âœ… ç¯å¢ƒ Patch å·²åº”ç”¨ (26ç»´)")

# # =================================================================
# # 2. é…ç½®
# # =================================================================
# LOG_DIR = './runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2026-02-07-19-09-38'
# SAVE_NAME = 'safety_gym_raw_26dim.npz' # âš ï¸ æ”¹åï¼æ ‡è®°ä¸º rawï¼Œé¿å…æ··æ·†
# NUM_SAMPLES = 200000 
# ENV_ID = 'SafetyPointGoal1-v0'

# # =================================================================
# # 3. è¾…åŠ©å‡½æ•°
# # =================================================================
# def convert_to_numpy(data):
#     if isinstance(data, torch.Tensor): data = data.detach().cpu().numpy()
#     if isinstance(data, np.ndarray):
#         if data.ndim > 1 and data.shape[0] == 1: data = data.squeeze(0)
#         if data.ndim == 0: data = data.item()
#     return data

# if __name__ == '__main__':
#     # åŠ è½½æ¨¡å‹
#     evaluator = omnisafe.Evaluator()
#     evaluator.load_saved(save_dir=LOG_DIR, model_name='epoch-500.pt')
    
#     # è¿™é‡Œçš„ env æ˜¯è¢« Wrap è¿‡çš„ï¼Œè¾“å‡ºçš„æ˜¯ Normalized Obs
#     env = evaluator._env 
    
#     # è·å– Agent (Actor)
#     # æ³¨æ„ï¼šæˆ‘ä»¬ä½¿ç”¨ evaluator.agent.predictï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†å½’ä¸€åŒ–è¾“å…¥
#     agent = evaluator.agent

#     # æ•°æ®å®¹å™¨
#     dataset = {'observations': [], 'actions': [], 'costs': [], 'terminals': [], 'timeouts': []}

#     # Reset æ‹¿åˆ°çš„æ˜¯ Normalized Obs
#     norm_obs, _ = env.reset()
#     collected_steps = 0
    
#     print(f"\nïš€ å¼€å§‹é‡‡é›† {NUM_SAMPLES} æ­¥ çœŸÂ·åŸå§‹æ•°æ® (Raw Data)...")

#     while collected_steps < NUM_SAMPLES:
        
#         # 1. ç­–ç•¥å†³ç­– (PPO éœ€è¦ Normalized Obs)
#         obs_tensor = torch.as_tensor(norm_obs, dtype=torch.float32).to(agent.device)
#         act, _ = agent.predict(obs_tensor, deterministic=True)
#         act_cpu = act.squeeze(0).cpu()
        
#         # 2. ï”¥ã€æ ¸å¿ƒä¿®æ”¹ã€‘è·å– Raw Obs ç”¨äºå­˜å‚¨ ï”¥
#         # è°ƒç”¨æœ€åº•å±‚ç¯å¢ƒçš„ obs() æ–¹æ³•ï¼Œç»•è¿‡æ‰€æœ‰ Wrapper
#         # è¿™æ ·å­˜ä¸‹æ¥çš„æ‰æ˜¯çœŸå®çš„ç‰©ç†æ•°å€¼
#         raw_obs_data = env.unwrapped.obs() 
        
#         # 3. ç¯å¢ƒæ­¥è¿› (è¿”å›çš„æ˜¯ Normalized Next Obs)
#         next_norm_obs, reward, cost, terminated, truncated, info = env.step(act_cpu)
        
#         # è¯Šæ–­æ‰“å°
#         if collected_steps % 5000 == 0:
#             print(f"è¿›åº¦: {collected_steps}/{NUM_SAMPLES}")
#             # å¯ä»¥å¯¹æ¯”ä¸€ä¸‹ raw å’Œ norm çš„åŒºåˆ«
#             # print(f"Raw: {raw_obs_data[:3]} | Norm: {norm_obs[:3]}")

#         # 4. å­˜å‚¨ (å­˜ Raw Obs !)
#         dataset['observations'].append(convert_to_numpy(raw_obs_data)) 
#         dataset['actions'].append(convert_to_numpy(act_cpu))
#         dataset['costs'].append(convert_to_numpy(cost))
#         dataset['terminals'].append(terminated)
#         dataset['timeouts'].append(truncated)
        
#         norm_obs = next_norm_obs
#         collected_steps += 1
        
#         if terminated or truncated:
#             norm_obs, _ = env.reset()

#     # ä¿å­˜
#     print("\nï’¾ æ­£åœ¨ä¿å­˜...")
#     final_data = {k: np.array(v) for k, v in dataset.items()}
#     save_path = os.path.join(LOG_DIR, SAVE_NAME)
#     np.savez(save_path, **final_data)
    
#     # ï“Š æœ€ç»ˆä½“æ£€
#     obs_std = np.std(final_data['observations'], axis=0)
#     print(f"="*40)
#     print(f"âœ… é‡‡é›†å®Œæˆ: {save_path}")
#     print(f"ï“Š æ–°æ•°æ®ä½“æ£€æŠ¥å‘Š:")
#     print(f"   - è§‚æµ‹æ–¹å·®èŒƒå›´: {np.min(obs_std):.4f} / {np.max(obs_std):.4f}")
    
#     # è¿™ä¸€æ¬¡ï¼Œæ–¹å·®åº”è¯¥å‚å·®ä¸é½ï¼Œè€Œä¸æ˜¯éƒ½åœ¨ 1.0 é™„è¿‘
#     if np.max(obs_std) < 0.5:
#         print("âš ï¸ è­¦å‘Š: æ–¹å·®ä¾ç„¶å¾ˆå°ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–åˆ°äº† Raw Obsã€‚")
#     else:
#         print("ï‰ å®Œç¾ï¼æ–¹å·®åˆ†å¸ƒæ­£å¸¸ï¼Œè¿™æ‰æ˜¯çœŸæ­£çš„ Raw Dataã€‚")

# import os
# import torch
# import numpy as np
# import omnisafe
# import safety_gymnasium
# import gymnasium
# from safety_gymnasium.assets.geoms import Hazards
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
# from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0

# # =================================================================
# # 1. Monkey Patch (ä¿æŒä¸å˜)
# # =================================================================
# def patched_init(self, config):
#     self.lidar_num_bins = 16
#     self.lidar_max_dist = 3.0
#     self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
#     self.task_name = 'GoalLevel1_Reproduction'
#     config.update({'lidar_num_bins': 16, 'lidar_max_dist': 3.0, 'sensors_obs': self.sensors_obs, 'task_name': self.task_name})
#     GoalLevel0.__init__(self, config=config)
#     self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
#     self._add_geoms(Hazards(num=2, keepout=0.18))

# def patched_build_observation_space(self):
#     self.observation_space = gymnasium.spaces.Box(low=-np.inf, high=np.inf, shape=(26,), dtype=np.float32)

# def patched_obs(self):
#     # è¿™æ˜¯ç”Ÿæˆ Raw Obs çš„æ ¸å¿ƒå‡½æ•°
#     lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group) 
#     acc = self.agent.get_sensor('accelerometer')[:2]
#     vel = self.agent.get_sensor('velocimeter')[:2]
#     gyro = self.agent.get_sensor('gyro')[-1:]
#     mag = self.agent.get_sensor('magnetometer')[:2]
#     sensor_vec = np.concatenate([acc, vel, gyro, mag])
#     vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
#     x, y = vec[0], vec[1]
#     z = x + 1j * y
#     dist = np.exp(-np.abs(z)) 
#     angle = np.angle(z)
#     goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])
#     return np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)

# GoalLevel1.__init__ = patched_init
# GoalLevel1.build_observation_space = patched_build_observation_space
# GoalLevel1.obs = patched_obs
# print("âœ… ç¯å¢ƒ Patch å·²åº”ç”¨ (26ç»´)")

# # =================================================================
# # 2. é…ç½®
# # =================================================================
# LOG_DIR = './runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2026-02-07-19-09-38'
# SAVE_NAME = 'safety_gym_raw_26dim.npz' 
# NUM_SAMPLES = 200000 

# # =================================================================
# # 3. è¾…åŠ©å‡½æ•°
# # =================================================================
# def find_actor(obj, depth=0):
#     if depth > 4: return None
#     if hasattr(obj, 'predict') and callable(getattr(obj, 'predict')):
#         if not isinstance(obj, omnisafe.Evaluator): return obj
#     for attr_name in dir(obj):
#         if attr_name.startswith('__'): continue
#         try:
#             attr_obj = getattr(obj, attr_name)
#             res = find_actor(attr_obj, depth + 1)
#             if res: return res
#         except: continue
#     return None

# def convert_to_numpy(data):
#     if isinstance(data, torch.Tensor): data = data.detach().cpu().numpy()
#     if isinstance(data, np.ndarray):
#         if data.ndim > 1 and data.shape[0] == 1: data = data.squeeze(0)
#         if data.ndim == 0: data = data.item()
#     return data

# # ğŸ”¥ ã€æ ¸å¿ƒä¿®å¤ã€‘å¢å¼ºç‰ˆç¯å¢ƒæŒ–æ˜å‡½æ•° ğŸ”¥
# def get_base_env(env):
#     """èƒ½å¤Ÿè¯†åˆ« SafetyGym .task ç»“æ„çš„æ·±åº¦æŒ–æ˜æœº"""
#     current = env
#     depth = 0
#     print("\nğŸ” æ­£åœ¨æŒ–æ˜åº•å±‚ç¯å¢ƒç»“æ„...")
    
#     while True:
#         env_type = type(current).__name__
#         print(f"   [Layer {depth}] Type: {env_type}")
        
#         # 1. æ£€æŸ¥æ˜¯å¦æœ‰ .task (SafetyGym ç‰¹æœ‰ç»“æ„)
#         if hasattr(current, 'task'):
#             print(f"     âœ… å‘ç° .task å±æ€§! å°è¯•è®¿é—® task.obs()...")
#             if hasattr(current.task, 'obs'):
#                 return current.task # æ‰¾åˆ°äº†ï¼
        
#         # 2. æ£€æŸ¥æœ¬èº«æ˜¯å¦æœ‰ .obs (æˆ‘ä»¬ Patch çš„å°±æ˜¯è¿™ä¸ª)
#         # æ³¨æ„ï¼šæœ‰äº› Wrapper ä¹Ÿä¼šè½¬å‘ .obsï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ç¡®ä¿å®ƒæ˜¯ç»‘å®šçš„æ–¹æ³•
#         if hasattr(current, 'obs') and callable(getattr(current, 'obs')):
#              # æ’é™¤æ‰åªæ˜¯ getattr è½¬å‘çš„æƒ…å†µï¼Œç¡®è®¤ä¸€ä¸‹
#              return current
        
#         # 3. ç»§ç»­å‘ä¸‹æŒ–
#         if hasattr(current, '_env'):
#             current = current._env
#         elif hasattr(current, 'env'):
#             current = current.env
#         else:
#             # æŒ–åˆ°åº•äº†
#             print(f"   âŒ Layer {depth} æ˜¯æœ€åº•å±‚ï¼Œä½†æ²¡æœ‰å‘ç° .obs() æˆ– .task")
#             print(f"      Available attrs: {[a for a in dir(current) if not a.startswith('_')]}")
#             raise AttributeError("âŒ æ— æ³•æ‰¾åˆ°åº•å±‚ç¯å¢ƒï¼è¯·æˆªå›¾å‘ç»™åŠ©æ‰‹åˆ†æã€‚")
        
#         depth += 1
#         if depth > 20: # é˜²æ­¢æ­»å¾ªç¯
#             raise RecursionError("ç¯å¢ƒåŒ…è£…å±‚çº§è¿‡æ·± (>20)ï¼")

# if __name__ == '__main__':
#     # 1. åŠ è½½ PPO
#     evaluator = omnisafe.Evaluator()
#     model_loaded = False
#     for mf in ['epoch-500.pt', 'model.pt']:
#         try:
#             evaluator.load_saved(save_dir=LOG_DIR, model_name=mf)
#             print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {mf}")
#             model_loaded = True
#             break
#         except: continue
    
#     if not model_loaded:
#         raise FileNotFoundError(f"âŒ åœ¨ {LOG_DIR} æ²¡æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
    
#     actor = find_actor(evaluator)
#     if actor is None:
#         try: actor = evaluator.actor
#         except: raise RuntimeError("æ— æ³•æ‰¾åˆ° Actor ç½‘ç»œ")

#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
#     if hasattr(actor, 'to'): actor.to(device)
    
#     env = evaluator._env 
    
#     # ğŸ”¥ æŒ–æ˜åº•å±‚ç¯å¢ƒ
#     base_env = get_base_env(env)
#     print(f"âœ… æˆåŠŸé”å®šåº•å±‚ç¯å¢ƒ: {base_env}")

#     # 2. å‡†å¤‡é‡‡é›†
#     dataset = {'observations': [], 'actions': [], 'costs': [], 'terminals': [], 'timeouts': []}
    
#     norm_obs, _ = env.reset()
#     collected_steps = 0
    
#     print(f"\nğŸš€ å¼€å§‹é‡‡é›† {NUM_SAMPLES} æ­¥ çœŸÂ·åŸå§‹æ•°æ® (Raw Data)...")
    
#     while collected_steps < NUM_SAMPLES:
        
#         # A. PPO å†³ç­– (ä½¿ç”¨ Normalized Obs)
#         with torch.no_grad():
#             obs_tensor = torch.as_tensor(norm_obs, dtype=torch.float32).to(device)
#             if obs_tensor.ndim == 1: obs_tensor = obs_tensor.unsqueeze(0)
#             act = actor.predict(obs_tensor, deterministic=True)
        
#         act_cpu = act.squeeze(0).cpu()
        
#         # B. ğŸ”¥ è·å– Raw Obs ğŸ”¥
#         # å¦‚æœ base_env æ˜¯ task å¯¹è±¡ï¼Œç›´æ¥è°ƒç”¨
#         # å¦‚æœ base_env æ˜¯ç¯å¢ƒå¯¹è±¡ï¼Œä¹Ÿç›´æ¥è°ƒç”¨
#         raw_obs_data = base_env.obs() 
        
#         # C. ç¯å¢ƒæ­¥è¿›
#         next_norm_obs, reward, cost, terminated, truncated, info = env.step(act_cpu)
        
#         # D. å­˜å‚¨
#         dataset['observations'].append(convert_to_numpy(raw_obs_data)) 
#         dataset['actions'].append(convert_to_numpy(act_cpu))
#         dataset['costs'].append(convert_to_numpy(cost))
#         dataset['terminals'].append(terminated)
#         dataset['timeouts'].append(truncated)
        
#         norm_obs = next_norm_obs
#         collected_steps += 1
        
#         if terminated or truncated:
#             norm_obs, _ = env.reset()
            
#         if collected_steps % 10000 == 0:
#             print(f"è¿›åº¦: {collected_steps}/{NUM_SAMPLES}")

#     # 3. ä¿å­˜
#     print("\nğŸ’¾ æ­£åœ¨ä¿å­˜...")
#     final_data = {k: np.array(v) for k, v in dataset.items()}
#     save_path = os.path.join(LOG_DIR, SAVE_NAME)
#     np.savez(save_path, **final_data)
    
#     print(f"âœ… é‡‡é›†å®Œæˆ: {save_path}")
    
#     # 4. å†æ¬¡ä½“æ£€
#     obs_std = np.std(final_data['observations'], axis=0)
#     print(f"ğŸ“Š æ–°æ•°æ®è§‚æµ‹æ–¹å·®èŒƒå›´: {np.min(obs_std):.4f} / {np.max(obs_std):.4f}")
    
#     if np.max(obs_std) < 0.5:
#         print("âš ï¸ è­¦å‘Š: æ–¹å·®ä¾ç„¶å¾ˆå°ï¼Œå¯èƒ½æ²¡æ‹¿åˆ°çœŸæ•°æ®ï¼")
#     else:
#         print("ğŸ‰ å®Œç¾ï¼æ–¹å·®åˆ†å¸ƒå‚å·®ä¸é½ï¼Œè¿™æ‰æ˜¯çœŸæ­£çš„ Raw Dataã€‚")



import os
import torch
import numpy as np
import omnisafe
import safety_gymnasium
import gymnasium
from safety_gymnasium.assets.geoms import Hazards
from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0

# =================================================================
# 1. Monkey Patch (å¿…é¡»åŠ ï¼Œç¡®ä¿ç¯å¢ƒæ˜¯ 26 ç»´)
# =================================================================
def patched_init(self, config):
    self.lidar_num_bins = 16
    self.lidar_max_dist = 3.0
    self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
    self.task_name = 'GoalLevel1_Reproduction'
    config.update({'lidar_num_bins': 16, 'lidar_max_dist': 3.0, 'sensors_obs': self.sensors_obs, 'task_name': self.task_name})
    GoalLevel0.__init__(self, config=config)
    self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
    self._add_geoms(Hazards(num=2, keepout=0.18))

def patched_build_observation_space(self):
    self.observation_space = gymnasium.spaces.Box(low=-np.inf, high=np.inf, shape=(26,), dtype=np.float32)

def patched_obs(self):
    # è¿™æ˜¯ç”Ÿæˆ Raw Obs çš„æ ¸å¿ƒå‡½æ•°
    lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group) 
    acc = self.agent.get_sensor('accelerometer')[:2]
    vel = self.agent.get_sensor('velocimeter')[:2]
    gyro = self.agent.get_sensor('gyro')[-1:]
    mag = self.agent.get_sensor('magnetometer')[:2]
    sensor_vec = np.concatenate([acc, vel, gyro, mag])
    vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
    x, y = vec[0], vec[1]
    z = x + 1j * y
    dist = np.exp(-np.abs(z)) 
    angle = np.angle(z)
    goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])
    return np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)

GoalLevel1.__init__ = patched_init
GoalLevel1.build_observation_space = patched_build_observation_space
GoalLevel1.obs = patched_obs
print("âœ… ç¯å¢ƒ Patch å·²åº”ç”¨ (26ç»´)")

# =================================================================
# 2. é…ç½®
# =================================================================
LOG_DIR = './runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2026-02-07-19-09-38'
SAVE_NAME = 'safety_gym_raw_26dim.npz' 
NUM_SAMPLES = 200000 

# =================================================================
# 3. è¾…åŠ©å‡½æ•°
# =================================================================
def find_actor(obj, depth=0):
    if depth > 4: return None
    if hasattr(obj, 'predict') and callable(getattr(obj, 'predict')):
        if not isinstance(obj, omnisafe.Evaluator): return obj
    for attr_name in dir(obj):
        if attr_name.startswith('__'): continue
        try:
            attr_obj = getattr(obj, attr_name)
            res = find_actor(attr_obj, depth + 1)
            if res: return res
        except: continue
    return None

def convert_to_numpy(data):
    if isinstance(data, torch.Tensor): data = data.detach().cpu().numpy()
    if isinstance(data, np.ndarray):
        if data.ndim > 1 and data.shape[0] == 1: data = data.squeeze(0)
        if data.ndim == 0: data = data.item()
    return data

# ğŸ”¥ æŒ–æ˜åº•å±‚ç¯å¢ƒç»“æ„ (ä¸ºäº†è·å– Raw Obs)
def get_base_env(env):
    current = env
    depth = 0
    print("\nğŸ” æ­£åœ¨æŒ–æ˜åº•å±‚ç¯å¢ƒç»“æ„...")
    while True:
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰ .task
        if hasattr(current, 'task') and hasattr(current.task, 'obs'):
            return current.task
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰ .obs (Patch çš„æƒ…å†µ)
        if hasattr(current, 'obs') and callable(getattr(current, 'obs')):
             return current
        # 3. å‘ä¸‹æŒ–
        if hasattr(current, '_env'): current = current._env
        elif hasattr(current, 'env'): current = current.env
        else:
            raise AttributeError("âŒ æ— æ³•æ‰¾åˆ°åº•å±‚ç¯å¢ƒï¼")
        depth += 1
        if depth > 20: raise RecursionError("ç¯å¢ƒå±‚çº§è¿‡æ·±")

if __name__ == '__main__':
    # 1. åŠ è½½ PPO
    evaluator = omnisafe.Evaluator()
    model_loaded = False
    for mf in ['epoch-500.pt', 'model.pt']:
        try:
            evaluator.load_saved(save_dir=LOG_DIR, model_name=mf)
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {mf}")
            model_loaded = True
            break
        except: continue
    
    if not model_loaded:
        raise FileNotFoundError(f"âŒ åœ¨ {LOG_DIR} æ²¡æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
    
    actor = find_actor(evaluator)
    if actor is None:
        raise RuntimeError("æ— æ³•æ‰¾åˆ° Actor ç½‘ç»œ")

    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    if hasattr(actor, 'to'): actor.to(device)
    
    env = evaluator._env 
    base_env = get_base_env(env)
    print(f"âœ… æˆåŠŸé”å®šåº•å±‚ç¯å¢ƒ: {base_env}")

    # 2. å‡†å¤‡é‡‡é›†
    dataset = {'observations': [], 'actions': [], 'costs': [], 'terminals': [], 'timeouts': []}
    
    norm_obs, _ = env.reset()
    collected_steps = 0
    
    print(f"\nğŸš€ å¼€å§‹é‡‡é›† {NUM_SAMPLES} æ­¥ çœŸÂ·åŸå§‹æ•°æ® (Raw Data)...")
    
    while collected_steps < NUM_SAMPLES:
        
        # A. PPO å†³ç­–
        with torch.no_grad():
            if isinstance(norm_obs, np.ndarray):
                obs_tensor = torch.as_tensor(norm_obs, dtype=torch.float32).to(device).unsqueeze(0)
            else:
                obs_tensor = norm_obs.to(device).unsqueeze(0)
                
            act = actor.predict(obs_tensor, deterministic=True)
        
        # ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘å‡†å¤‡ä¼ ç»™ç¯å¢ƒçš„åŠ¨ä½œ
        # 1. .cpu(): è§£å†³ Device Mismatch
        # 2. .squeeze(0): è§£å†³ Dimension Mismatch (1,2) -> (2,)
        act_env = act.cpu().squeeze(0)
        
        # B. è·å– Raw Obs
        raw_obs_data = base_env.obs() 
        
        # C. ç¯å¢ƒæ­¥è¿› (ä¼ å…¥ä¿®å¤åçš„ act_env)
        res = env.step(act_env)
        
        # è§£åŒ…è¿”å›å€¼
        if len(res) == 6:
            next_norm_obs, reward, cost, terminated, truncated, _ = res
        elif len(res) == 5:
            next_norm_obs, reward, cost, terminated, truncated = res
        
        # D. å­˜å‚¨ (å­˜ act_env çš„ numpy ç‰ˆæœ¬)
        dataset['observations'].append(convert_to_numpy(raw_obs_data)) 
        dataset['actions'].append(convert_to_numpy(act_env))
        dataset['costs'].append(convert_to_numpy(cost))
        dataset['terminals'].append(convert_to_numpy(terminated))
        dataset['timeouts'].append(convert_to_numpy(truncated))
        
        norm_obs = next_norm_obs
        collected_steps += 1
        
        if terminated or truncated:
            norm_obs, _ = env.reset()
            
        if collected_steps % 10000 == 0:
            print(f"è¿›åº¦: {collected_steps}/{NUM_SAMPLES}")

    # 3. ä¿å­˜
    print("\nğŸ’¾ æ­£åœ¨ä¿å­˜...")
    final_data = {k: np.array(v) for k, v in dataset.items()}
    save_path = os.path.join(LOG_DIR, SAVE_NAME)
    np.savez(save_path, **final_data)
    
    print(f"âœ… é‡‡é›†å®Œæˆ: {save_path}")
    
    # 4. ä½“æ£€
    obs_std = np.std(final_data['observations'], axis=0)
    print(f"ğŸ“Š æ–°æ•°æ®è§‚æµ‹æ–¹å·®èŒƒå›´: {np.min(obs_std):.4f} / {np.max(obs_std):.4f}")
    
    # ç»Ÿè®¡æˆåŠŸç‡
    terminals = final_data['terminals']
    timeouts = final_data['timeouts']
    costs = final_data['costs']
    success_rate = np.sum(terminals) / (np.sum(terminals) + np.sum(timeouts))
    print(f"ğŸ“Š é‡‡é›†è½¨è¿¹æˆåŠŸç‡: {success_rate*100:.1f}%")
    if success_rate < 0.05:
        print("âš ï¸ è­¦å‘Š: æˆåŠŸç‡æä½ï¼è™½ç„¶ä»£ç è·‘é€šäº†ï¼Œä½†é‡‡é›†çš„æ•°æ®å…¨æ˜¯â€˜è½¬åœˆåœˆâ€™çš„æ•°æ®ã€‚")
        print("   -> å»ºè®®: é‡è®­ PPO æ¨¡å‹ (æˆ‘å¯ä»¥ç»™ä½ é‡è®­è„šæœ¬)ã€‚")