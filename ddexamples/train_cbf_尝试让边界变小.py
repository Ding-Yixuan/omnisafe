import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
import matplotlib.pyplot as plt

# =================================================================
# 1. ÈÖçÁΩÆÂèÇÊï∞
# =================================================================
CONFIG = {
    'dataset_path': './data_pro/ppolag_ÊµãËØïdata.npz',  # üëà Á°Æ‰øùÊñá‰ª∂ÂêçÂØπ
    'obs_dim': 26,
    'hidden_dim': 256,
    'lr': 1e-3,              # Á®çÂæÆË∞ÉÂ∞è‰∏ÄÁÇπÔºåÊõ¥Á®≥ÂÆö
    'batch_size': 256,       # 128 Safe + 128 Unsafe
    'train_steps': 20000,    # üëà ‰øÆÊ≠£Ôºö2‰∏áÊ≠•Ë∂≥Â§ü‰∫Ü (Á∫¶100‰∏™Epoch)Ôºå‰∏çÈúÄË¶Å200‰∏áÊ≠•ÔºÅ
    'eval_freq': 500,        # ÊØè500Ê≠•È™åËØÅ‰∏ÄÊ¨°
    'device': 'cuda:0',
    'save_dir': './ÁúãcbfÊï∞ÊçÆ/ppolag_ÊµãËØïdata2ËÆ©ËæπÁïåÂèòÂ∞è'
}

# =================================================================
# 2. CBF ÁΩëÁªúÂÆö‰πâ (‰øùÊåÅ‰∏çÂèò)
# =================================================================
class CBFNetwork(nn.Module):
    def __init__(self, obs_dim, hidden_dim=256):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(obs_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1) # ËæìÂá∫ h(x)
        )
        
    def forward(self, x):
        return self.net(x)

# =================================================================
# 3. Êï∞ÊçÆÈõÜ (Â¢ûÂä†‰∫Ü Train/Val ÂàíÂàÜ & Âπ≥Ë°°ÈááÊ†∑)
# =================================================================
class BalancedCBFDataset:
    def __init__(self, data_path, device):
        print(f"üìÇ Loading data from {data_path}...")
        raw_data = np.load(data_path)
        
        # Âä†ËΩΩÊï∞ÊçÆ
        full_obs = torch.from_numpy(raw_data['obs']).float().to(device)
        full_lbl = torch.from_numpy(raw_data['is_safe']).float().to(device)
        
        # ÁÆÄÂçïÁöÑÂàíÂàÜÈÄªËæëÔºöÂâç 90% ËÆ≠ÁªÉÔºåÂêé 10% È™åËØÅ
        total_len = len(full_lbl)
        split_idx = int(total_len * 0.9)
        
        self.train_obs = full_obs[:split_idx]
        self.train_lbl = full_lbl[:split_idx]
        
        self.val_obs = full_obs[split_idx:]
        self.val_lbl = full_lbl[split_idx:]
            
        # --- ÂÖ≥ÈîÆÔºöÂàÜÁ¶ªÁ¥¢ÂºïÁî®‰∫éÂπ≥Ë°°ÈááÊ†∑ (‰ªÖÈíàÂØπËÆ≠ÁªÉÈõÜ) ---
        self.safe_indices = (self.train_lbl == 1).nonzero(as_tuple=True)[0]
        self.unsafe_indices = (self.train_lbl == 0).nonzero(as_tuple=True)[0]
        
        print(f"üìä Training Stats:")
        print(f"   - Safe samples: {len(self.safe_indices)}")
        print(f"   - Unsafe samples: {len(self.unsafe_indices)}")
        
        if len(self.unsafe_indices) == 0:
            raise ValueError("‚ùå ËÆ≠ÁªÉÈõÜ‰∏≠Ê≤°Êúâ‰∏çÂÆâÂÖ®Ê†∑Êú¨ÔºÅÊó†Ê≥ïËÆ≠ÁªÉÊúâÊïàËæπÁïåÔºÅ")

    def get_train_batch(self, batch_size):
        """ Âº∫Âà∂ 50% Safe, 50% Unsafe """
        half = batch_size // 2
        
        # ÈöèÊú∫ÈááÊ†∑ Safe
        idx_safe = self.safe_indices[torch.randint(0, len(self.safe_indices), (half,))]
        
        # ÈöèÊú∫ÈááÊ†∑ Unsafe (ÂÖÅËÆ∏ÈáçÂ§çÔºåÂõ†‰∏∫ Unsafe Ê†∑Êú¨ÈÄöÂ∏∏ÂæàÂ∞ë)
        idx_unsafe = self.unsafe_indices[torch.randint(0, len(self.unsafe_indices), (half,))]
        
        batch_obs = torch.cat([self.train_obs[idx_safe], self.train_obs[idx_unsafe]])
        batch_labels = torch.cat([self.train_lbl[idx_safe], self.train_lbl[idx_unsafe]])
        
        return batch_obs, batch_labels

    def get_val_batch(self, batch_size):
        """ È™åËØÅÈõÜ‰∏çÈúÄË¶ÅÂπ≥Ë°°ÔºåÈöèÊú∫ÂèñÂç≥ÂèØ """
        idx = torch.randint(0, len(self.val_lbl), (batch_size,))
        return self.val_obs[idx], self.val_lbl[idx]

# =================================================================
# 4. ‰∏ªËÆ≠ÁªÉÂæ™ÁéØ
# =================================================================
def train():
    os.makedirs(CONFIG['save_dir'], exist_ok=True)
    device = torch.device(CONFIG['device'])
    
    # 1. ÂáÜÂ§áÊï∞ÊçÆ
    dataset = BalancedCBFDataset(CONFIG['dataset_path'], device)
    
    # 2. ËÆ°ÁÆóÂπ∂Â∫îÁî®ÂΩí‰∏ÄÂåñ (‰ΩøÁî®ËÆ≠ÁªÉÈõÜÁªüËÆ°Èáè)
    # Ê≥®ÊÑèÔºöÊàë‰ª¨Ë¶Å‰øùÂ≠òËøô‰∏™ normalization ÂèÇÊï∞ÔºåÁîªÂõæÊó∂ÂøÖÈ°ªË¶ÅÁî®ÔºÅ
    obs_cpu = dataset.train_obs.cpu().numpy()
    mins = torch.from_numpy(obs_cpu.min(axis=0)).to(device)
    maxs = torch.from_numpy(obs_cpu.max(axis=0)).to(device)
    maxs[maxs == mins] += 1.0 # Èò≤Èô§Èõ∂
    
    # ‰øùÂ≠òÂΩí‰∏ÄÂåñÂèÇÊï∞
    np.savez(os.path.join(CONFIG['save_dir'], 'cbf_normalization.npz'), 
             mins=mins.cpu().numpy(), maxs=maxs.cpu().numpy())
    print("‚úÖ Normalization params saved.")
    
    # In-place ÂΩí‰∏ÄÂåñÂáΩÊï∞
    def normalize_tensor(tensor):
        normed = (tensor - mins) / (maxs - mins)
        normed = 2 * normed - 1
        return torch.clamp(normed, -5.0, 5.0) # Clip ÊéâÂºÇÂ∏∏ÂÄº
    
    dataset.train_obs = normalize_tensor(dataset.train_obs)
    dataset.val_obs = normalize_tensor(dataset.val_obs)
    print("‚úÖ Data Normalized.")

    # 3. Ê®°Âûã‰∏é‰ºòÂåñÂô®
    cbf_net = CBFNetwork(CONFIG['obs_dim'], CONFIG['hidden_dim']).to(device)
    optimizer = optim.Adam(cbf_net.parameters(), lr=CONFIG['lr'])
    criterion = nn.MSELoss() # ÂõûÂΩí Loss (ÈÄºËøë +1/-1)

    best_val_loss = float('inf')
    loss_history = []
    val_history = []

    print(f"üöÄ Start Training CBF...")
    
    for step in range(CONFIG['train_steps']):
        # --- Training ---
        cbf_net.train()
        batch_obs, batch_labels = dataset.get_train_batch(CONFIG['batch_size'])
        
        # Label Êò†Â∞Ñ: 0 -> -1 (Unsafe), 1 -> +1 (Safe)
        target_h = 2 * batch_labels - 1 
        target_h = target_h.unsqueeze(1)
        
        pred_h = cbf_net(batch_obs)
        loss = criterion(pred_h, target_h)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # --- Validation & Logging ---
        if step % CONFIG['eval_freq'] == 0:
            cbf_net.eval()
            with torch.no_grad():
                val_obs, val_lbl = dataset.get_val_batch(CONFIG['batch_size'])
                val_target = 2 * val_lbl - 1
                val_pred = cbf_net(val_obs)
                val_loss = criterion(val_pred, val_target.unsqueeze(1))
                
                loss_history.append(loss.item())
                val_history.append(val_loss.item())
                
                print(f"Step {step:5d} | Train Loss: {loss.item():.5f} | Val Loss: {val_loss.item():.5f}")
                
                # ‰øùÂ≠òÊúÄ‰Ω≥Ê®°Âûã
                if val_loss.item() < best_val_loss:
                    best_val_loss = val_loss.item()
                    torch.save(cbf_net.state_dict(), os.path.join(CONFIG['save_dir'], 'best_cbf_model.pt'))
                    print(f"  üåü New Best Model Saved! (Val Loss: {best_val_loss:.5f})")

    # ÁîªÂõæ
    plt.figure(figsize=(10,5))
    plt.plot(loss_history, label='Train Loss')
    plt.plot(val_history, label='Val Loss')
    plt.legend()
    plt.title("CBF Training Curve")
    plt.savefig(os.path.join(CONFIG['save_dir'], 'cbf_loss_curve.png'))
    print("üèÅ Training Finished.")

if __name__ == '__main__':
    train()