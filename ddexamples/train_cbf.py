# import torch
# import torch.nn as nn
# import torch.optim as optim
# import numpy as np
# import os
# import matplotlib.pyplot as plt

# # =================================================================
# # 1. é…ç½®å‚æ•°
# # =================================================================
# CONFIG = {
#     'dataset_path': './data_pro/ppolag_zuida.npz',  # ğŸ‘ˆ ç¡®ä¿è¿™é‡ŒæŒ‡å‘ä½ æœ€æ–°çš„ raw æ•°æ®
#     'obs_dim': 26,
#     'hidden_dim': 256,
#     'lr': 1e-3,
#     'batch_size': 256,      # æ¯æ¬¡è®­ç»ƒå– 128ä¸ªå®‰å…¨ + 128ä¸ªä¸å®‰å…¨
#     'train_steps': 2000000,   # è®­ç»ƒæ­¥æ•°
#     'device': 'cuda:0',
#     'save_dir': './cbf_checkpoints/cbf2'
# }

# # =================================================================
# # 2. CBF ç½‘ç»œå®šä¹‰
# # =================================================================
# class CBFNetwork(nn.Module):
#     def __init__(self, obs_dim, hidden_dim=256):
#         super().__init__()
#         # ä¸€ä¸ªç®€å•çš„ MLPï¼Œè¾“å‡º 1 ç»´æ ‡é‡
#         self.net = nn.Sequential(
#             nn.Linear(obs_dim, hidden_dim),
#             nn.ReLU(),
#             nn.Linear(hidden_dim, hidden_dim),
#             nn.ReLU(),
#             nn.Linear(hidden_dim, 1) # è¾“å‡º h(x)
#         )
        
#     def forward(self, x):
#         return self.net(x)

# # =================================================================
# # 3. æ•°æ®é›†ä¸å¹³è¡¡é‡‡æ ·å™¨ (å…³é”®ï¼)
# # =================================================================
# class BalancedCBFDataset:
#     def __init__(self, data_path, device):
#         print(f"ğŸ“‚ Loading data from {data_path}...")
#         raw_data = np.load(data_path)
        
#         self.obs = torch.from_numpy(raw_data['obs']).float().to(device)
#         # is_safe: 1=Safe, 0=Unsafe
#         self.labels = torch.from_numpy(raw_data['is_safe']).float().to(device)
        
#         # åˆ†ç¦»å®‰å…¨å’Œä¸å®‰å…¨æ•°æ®çš„ç´¢å¼•
#         # æ³¨æ„: TTC > Threshold æ˜¯å®‰å…¨ (1), å¦åˆ™æ˜¯ä¸å®‰å…¨ (0)
#         self.safe_indices = (self.labels == 1).nonzero(as_tuple=True)[0]
#         self.unsafe_indices = (self.labels == 0).nonzero(as_tuple=True)[0]
        
#         print(f"ğŸ“Š Data Statistics:")
#         print(f"   - Total: {len(self.labels)}")
#         print(f"   - Safe samples: {len(self.safe_indices)}")
#         print(f"   - Unsafe samples: {len(self.unsafe_indices)}")
        
#         if len(self.unsafe_indices) == 0:
#             print("âŒ ä¸¥é‡è­¦å‘Šï¼šæ•°æ®é›†ä¸­æ²¡æœ‰ä¸å®‰å…¨æ ·æœ¬ï¼CBF æ— æ³•è®­ç»ƒè¾¹ç•Œï¼")
#             print("ğŸ’¡ å»ºè®®ï¼šåœ¨é‡‡é›†æ—¶è°ƒå¤§ TTC_THRESHOLD (æ¯”å¦‚ 1.5 æˆ– 2.0)ï¼Œæˆ–è€…è®©æœºå™¨äººç¨å¾®'æµª'ä¸€ç‚¹ã€‚")
            
#     def get_batch(self, batch_size):
#         """ æ¯æ¬¡ä»ä¸¤å †æ•°æ®é‡Œå„å–ä¸€åŠ """
#         half_batch = batch_size // 2
        
#         # éšæœºé‡‡æ ·ç´¢å¼•
#         idx_safe = self.safe_indices[torch.randint(0, len(self.safe_indices), (half_batch,))]
        
#         # å¦‚æœä¸å®‰å…¨æ ·æœ¬å¤ªå°‘ï¼Œå…è®¸é‡å¤é‡‡æ ·
#         idx_unsafe = self.unsafe_indices[torch.randint(0, len(self.unsafe_indices), (half_batch,))]
        
#         batch_obs = torch.cat([self.obs[idx_safe], self.obs[idx_unsafe]])
#         batch_labels = torch.cat([self.labels[idx_safe], self.labels[idx_unsafe]])
        
#         return batch_obs, batch_labels

# # =================================================================
# # 4. å½’ä¸€åŒ–å·¥å…· (å¿…é¡»å’Œ Diffuser ä¿æŒä¸€è‡´)
# # =================================================================
# # CBF ä¹Ÿéœ€è¦å½’ä¸€åŒ–è¾“å…¥ï¼Œæˆ‘ä»¬ç›´æ¥è®¡ç®—å¹¶åœ¨è®­ç»ƒå‰å¤„ç†
# def normalize_data(obs, mins, maxs):
#     # [0, 1]
#     x_norm = (obs - mins) / (maxs - mins)
#     # [-1, 1]
#     return 2 * x_norm - 1

# # =================================================================
# # 5. ä¸»è®­ç»ƒå¾ªç¯
# # =================================================================
# def train():
#     os.makedirs(CONFIG['save_dir'], exist_ok=True)
#     device = torch.device(CONFIG['device'])
    
#     # 1. å‡†å¤‡æ•°æ®
#     dataset = BalancedCBFDataset(CONFIG['dataset_path'], device)
    
#     # è®¡ç®—å½’ä¸€åŒ–å‚æ•° (ä½¿ç”¨å…¨éƒ¨æ•°æ®è®¡ç®—)
#     # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬é‡æ–°è®¡ç®—ä¸€éï¼Œæˆ–è€…ç›´æ¥åŠ è½½ Diffuser çš„ normalization.npz ä¹Ÿå¯ä»¥
#     # ä¸ºäº†ç‹¬ç«‹æ€§ï¼Œæˆ‘ä»¬è¿™é‡Œé‡æ–°ç®—ä¸€éå¹¶ä¿å­˜
#     all_obs_cpu = dataset.obs.cpu().numpy()
#     mins = torch.from_numpy(all_obs_cpu.min(axis=0)).to(device)
#     maxs = torch.from_numpy(all_obs_cpu.max(axis=0)).to(device)
#     # é˜²æ­¢é™¤é›¶
#     maxs[maxs == mins] += 1.0
    
#     np.savez(os.path.join(CONFIG['save_dir'], 'cbf_normalization.npz'), 
#              mins=mins.cpu().numpy(), maxs=maxs.cpu().numpy())
    
#     # 2. å½’ä¸€åŒ–æ•´ä¸ªæ•°æ®é›† (In-place)
#     dataset.obs = (dataset.obs - mins) / (maxs - mins)
#     dataset.obs = 2 * dataset.obs - 1
#     # å¼ºåˆ¶ Clip é˜²æ­¢æç«¯å€¼
#     dataset.obs = torch.clamp(dataset.obs, -1.0, 1.0)
    
#     print("âœ… Data Normalized and Ready.")

#     # 3. åˆå§‹åŒ–æ¨¡å‹
#     cbf_net = CBFNetwork(CONFIG['obs_dim'], CONFIG['hidden_dim']).to(device)
#     optimizer = optim.Adam(cbf_net.parameters(), lr=CONFIG['lr'])
    
#     # Loss å‡½æ•°
#     # æˆ‘ä»¬å¸Œæœ› Safe -> +1, Unsafe -> -1
#     # æ‰€ä»¥æˆ‘ä»¬å°† label (0, 1) æ˜ å°„åˆ° (-1, 1)
#     criterion = nn.MSELoss()

#     print(f"ğŸš€ Start Training CBF...")
    
#     loss_history = []
    
#     for step in range(CONFIG['train_steps']):
#         # è·å–å¹³è¡¡ Batch
#         batch_obs, batch_labels = dataset.get_batch(CONFIG['batch_size'])
        
#         # å°† Label ä» {0, 1} è½¬æ¢ä¸º {-1, 1}
#         # 0 -> -1 (Unsafe)
#         # 1 -> +1 (Safe)
#         target_h = 2 * batch_labels - 1
#         target_h = target_h.unsqueeze(1) # [Batch, 1]
        
#         # Forward
#         pred_h = cbf_net(batch_obs)
        
#         # Loss
#         loss = criterion(pred_h, target_h)
        
#         # Backward
#         optimizer.zero_grad()
#         loss.backward()
#         optimizer.step()
        
#         if step % 100 == 0:
#             loss_history.append(loss.item())
#             print(f"Step {step}/{CONFIG['train_steps']} | Loss: {loss.item():.6f}")
            
#     # ä¿å­˜æ¨¡å‹
#     save_path = os.path.join(CONFIG['save_dir'], 'cbf_model.pt')
#     torch.save(cbf_net.state_dict(), save_path)
#     print(f"ğŸ’¾ CBF Model saved to {save_path}")
    
#     # ç”»å›¾
#     plt.plot(loss_history)
#     plt.title("CBF Training Loss")
#     plt.savefig(os.path.join(CONFIG['save_dir'], 'cbf_loss.png'))

#     # ç®€å•æµ‹è¯•ä¸€ä¸‹
#     print("\nğŸ”¬ Testing Prediction:")
#     with torch.no_grad():
#         test_obs, test_lbl = dataset.get_batch(10)
#         preds = cbf_net(test_obs)
#         for i in range(10):
#             gt = "Safe (+1)" if test_lbl[i] > 0.5 else "Unsafe (-1)"
#             print(f"   GT: {gt} | Pred: {preds[i].item():.4f}")

# if __name__ == '__main__':
#     train()


import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
import matplotlib.pyplot as plt

# =================================================================
# 1. é…ç½®å‚æ•°
# =================================================================
CONFIG = {
    'dataset_path': './data_pro/ppolag_æµ‹è¯•data.npz',  # ğŸ‘ˆ ç¡®ä¿æ–‡ä»¶åå¯¹
    'obs_dim': 26,
    'hidden_dim': 256,
    'lr': 3e-4,              # ç¨å¾®è°ƒå°ä¸€ç‚¹ï¼Œæ›´ç¨³å®š
    'batch_size': 256,       # 128 Safe + 128 Unsafe
    'train_steps': 30000,    # ğŸ‘ˆ ä¿®æ­£ï¼š3ä¸‡æ­¥è¶³å¤Ÿäº† (çº¦150ä¸ªEpoch)
    'eval_freq': 1000,       # æ¯1000æ­¥éªŒè¯ä¸€æ¬¡
    'device': 'cuda:0',
    'save_dir': './çœ‹cbfæ•°æ®/ppolag_æµ‹è¯•data'
}

# =================================================================
# 2. CBF ç½‘ç»œå®šä¹‰ (ä¿æŒä¸å˜)
# =================================================================
class CBFNetwork(nn.Module):
    def __init__(self, obs_dim, hidden_dim=256):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(obs_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1) # è¾“å‡º h(x)
        )
        
    def forward(self, x):
        return self.net(x)

# =================================================================
# 3. æ•°æ®é›† (å¢åŠ äº† Train/Val åˆ’åˆ†)
# =================================================================
class BalancedCBFDataset:
    def __init__(self, data_path, device, mode='train', val_ratio=0.1):
        print(f"ğŸ“‚ Loading data from {data_path}...")
        raw_data = np.load(data_path)
        
        full_obs = torch.from_numpy(raw_data['obs']).float().to(device)
        full_lbl = torch.from_numpy(raw_data['is_safe']).float().to(device)
        
        # ç®€å•çš„åˆ’åˆ†é€»è¾‘ï¼šå–å 10% åšéªŒè¯
        total_len = len(full_lbl)
        split_idx = int(total_len * (1 - val_ratio))
        
        if mode == 'train':
            self.obs = full_obs[:split_idx]
            self.labels = full_lbl[:split_idx]
        else:
            self.obs = full_obs[split_idx:]
            self.labels = full_lbl[split_idx:]
            
        # åˆ†ç¦»ç´¢å¼•ç”¨äºå¹³è¡¡é‡‡æ ·
        self.safe_indices = (self.labels == 1).nonzero(as_tuple=True)[0]
        self.unsafe_indices = (self.labels == 0).nonzero(as_tuple=True)[0]
        
        print(f"[{mode.upper()}] Safe: {len(self.safe_indices)} | Unsafe: {len(self.unsafe_indices)}")
        
        if len(self.unsafe_indices) == 0 and mode == 'train':
            raise ValueError("âŒ è®­ç»ƒé›†ä¸­æ²¡æœ‰ä¸å®‰å…¨æ ·æœ¬ï¼æ— æ³•è®­ç»ƒï¼")

    def get_batch(self, batch_size):
        half = batch_size // 2
        # éšæœºé‡‡æ ·ï¼Œå…è®¸é‡å¤ (with replacement) ä»¥åº”å¯¹æ ·æœ¬å°‘çš„æƒ…å†µ
        idx_safe = self.safe_indices[torch.randint(0, len(self.safe_indices), (half,))]
        idx_unsafe = self.unsafe_indices[torch.randint(0, len(self.unsafe_indices), (half,))]
        
        batch_obs = torch.cat([self.obs[idx_safe], self.obs[idx_unsafe]])
        batch_labels = torch.cat([self.labels[idx_safe], self.labels[idx_unsafe]])
        
        return batch_obs, batch_labels

# =================================================================
# 4. ä¸»è®­ç»ƒå¾ªç¯
# =================================================================
def train():
    os.makedirs(CONFIG['save_dir'], exist_ok=True)
    device = torch.device(CONFIG['device'])
    
    # 1. å‡†å¤‡æ•°æ®
    train_set = BalancedCBFDataset(CONFIG['dataset_path'], device, mode='train')
    val_set = BalancedCBFDataset(CONFIG['dataset_path'], device, mode='val')
    
    # 2. è®¡ç®—å¹¶åº”ç”¨å½’ä¸€åŒ– (ä½¿ç”¨è®­ç»ƒé›†ç»Ÿè®¡é‡)
    # æ³¨æ„ï¼šValidation Set ä¹Ÿè¦ç”¨ Train Set çš„å‡å€¼æ–¹å·®æ¥å½’ä¸€åŒ–ï¼Œä¸¥è°¨ï¼
    obs_cpu = train_set.obs.cpu().numpy()
    mins = torch.from_numpy(obs_cpu.min(axis=0)).to(device)
    maxs = torch.from_numpy(obs_cpu.max(axis=0)).to(device)
    maxs[maxs == mins] += 1.0 # é˜²é™¤é›¶
    
    # ä¿å­˜å½’ä¸€åŒ–å‚æ•°ä¾›åç»­ä½¿ç”¨
    np.savez(os.path.join(CONFIG['save_dir'], 'cbf_normalization.npz'), 
             mins=mins.cpu().numpy(), maxs=maxs.cpu().numpy())
    
    # In-place å½’ä¸€åŒ–å‡½æ•°
    def apply_norm(dataset_obj):
        dataset_obj.obs = (dataset_obj.obs - mins) / (maxs - mins)
        dataset_obj.obs = 2 * dataset_obj.obs - 1
        dataset_obj.obs = torch.clamp(dataset_obj.obs, -1.0, 1.0)
    
    apply_norm(train_set)
    apply_norm(val_set)
    print("âœ… Data Normalized.")

    # 3. æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    cbf_net = CBFNetwork(CONFIG['obs_dim'], CONFIG['hidden_dim']).to(device)
    optimizer = optim.Adam(cbf_net.parameters(), lr=CONFIG['lr'])
    criterion = nn.MSELoss()

    best_val_loss = float('inf')
    loss_history = []
    val_history = []

    print(f"ğŸš€ Start Training...")
    
    for step in range(CONFIG['train_steps']):
        # --- Training ---
        cbf_net.train()
        batch_obs, batch_labels = train_set.get_batch(CONFIG['batch_size'])
        target_h = 2 * batch_labels - 1 # [0,1] -> [-1,1]
        target_h = target_h.unsqueeze(1)
        
        pred_h = cbf_net(batch_obs)
        loss = criterion(pred_h, target_h)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # --- Validation & Logging ---
        if step % CONFIG['eval_freq'] == 0:
            cbf_net.eval()
            with torch.no_grad():
                # éªŒè¯é›†ä¹Ÿé‡‡æ ·ä¸€ä¸ª Batch çœ‹çœ‹ Loss
                val_obs, val_lbl = val_set.get_batch(CONFIG['batch_size'])
                val_target = 2 * val_lbl - 1
                val_pred = cbf_net(val_obs)
                val_loss = criterion(val_pred, val_target.unsqueeze(1))
                
                loss_history.append(loss.item())
                val_history.append(val_loss.item())
                
                print(f"Step {step:5d} | Train Loss: {loss.item():.5f} | Val Loss: {val_loss.item():.5f}")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_loss.item() < best_val_loss:
                    best_val_loss = val_loss.item()
                    torch.save(cbf_net.state_dict(), os.path.join(CONFIG['save_dir'], 'best_cbf_model.pt'))
                    print(f"  ğŸŒŸ New Best Model Saved! (Val Loss: {best_val_loss:.5f})")

    # ç”»å›¾
    plt.figure(figsize=(10,5))
    plt.plot(loss_history, label='Train Loss')
    plt.plot(val_history, label='Val Loss')
    plt.legend()
    plt.title("CBF Training Curve")
    plt.savefig(os.path.join(CONFIG['save_dir'], 'cbf_loss_curve.png'))
    print("ğŸ Training Finished.")

if __name__ == '__main__':
    train()