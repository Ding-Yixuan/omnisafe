import os
# 1. å¼ºåˆ¶ä½¿ç”¨ EGL åç«¯ (è§£å†³æœåŠ¡å™¨æ— æ˜¾ç¤ºå™¨æŠ¥é”™)
os.environ['MUJOCO_GL'] = 'egl'

import torch
import torch.nn as nn
import numpy as np
import safety_gymnasium
import gymnasium
from safety_gymnasium.assets.geoms import Hazards
from safety_gymnasium.tasks.safe_navigation.goal.goal_level1 import GoalLevel1
from safety_gymnasium.tasks.safe_navigation.goal.goal_level0 import GoalLevel0
import imageio

# =================================================================
# 1. ç¯å¢ƒå®šä¹‰ (Monkey Patch) - å¿…é¡»ä¸è®­ç»ƒå®Œå…¨ä¸€è‡´ï¼
# =================================================================
def patched_init(self, config):
    self.lidar_num_bins = 16
    self.lidar_max_dist = 3.0
    self.sensors_obs = ['accelerometer', 'velocimeter', 'gyro', 'magnetometer']
    self.task_name = 'GoalLevel1_Reproduction'
    config.update({'lidar_num_bins': 16, 'lidar_max_dist': 3.0, 'sensors_obs': self.sensors_obs, 'task_name': self.task_name})
    GoalLevel0.__init__(self, config=config)
    # æ‰©å¤§ä¸€ç‚¹åœ°å›¾èŒƒå›´ï¼Œé˜²æ­¢åˆ·åœ¨å¢™å¤–
    self.placements_conf.extents = [-1.5, -1.5, 1.5, 1.5]
    self._add_geoms(Hazards(num=2, keepout=0.2))

def patched_obs(self):
    lidar_vec = self._obs_lidar(self.hazards.pos, self.hazards.group)
    acc = self.agent.get_sensor('accelerometer')[:2]
    vel = self.agent.get_sensor('velocimeter')[:2]
    gyro = self.agent.get_sensor('gyro')[-1:]
    mag = self.agent.get_sensor('magnetometer')[:2]
    sensor_vec = np.concatenate([acc, vel, gyro, mag])
    vec = (self.goal.pos - self.agent.pos) @ self.agent.mat
    x, y = vec[0], vec[1]
    z = x + 1j * y
    # âœ… å¿…é¡»ç¡®è®¤ï¼šè®­ç»ƒæ—¶ç”¨çš„æ˜¯ np.exp è¿˜æ˜¯ np.absï¼Ÿ
    # å¦‚æœä½ æœ€åç”¨ np.exp è®­ç»ƒçš„æ•°æ®ï¼Œè¿™é‡Œå¿…é¡»æ˜¯ np.exp
    dist = np.exp(-np.abs(z)) 
    angle = np.angle(z)
    goal_vec = np.array([dist, np.cos(angle), np.sin(angle)])
    return np.concatenate([sensor_vec, goal_vec, lidar_vec]).astype(np.float32)

GoalLevel1.__init__ = patched_init
GoalLevel1.obs = patched_obs

# =================================================================
# 2. æ¨¡å‹æ¶æ„ (å¿…é¡»ä¸è®­ç»ƒä¸€è‡´)
# =================================================================
class SinusoidalPosEmb(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim
    def forward(self, x):
        device = x.device
        half_dim = self.dim // 2
        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)
        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)
        emb = x[:, None] * emb[None, :]
        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)
        return emb

class TemporalUnet(nn.Module):
    def __init__(self, transition_dim, dim=256): 
        super().__init__()
        self.time_mlp = nn.Sequential(SinusoidalPosEmb(dim), nn.Linear(dim, dim * 4), nn.Mish(), nn.Linear(dim * 4, dim))
        self.down1 = nn.Sequential(nn.Conv1d(transition_dim, dim, 3, padding=1), nn.Mish())
        self.down2 = nn.Sequential(nn.Conv1d(dim, dim * 2, 3, padding=1), nn.Mish())
        self.down3 = nn.Sequential(nn.Conv1d(dim * 2, dim * 4, 3, padding=1), nn.Mish())
        self.up1 = nn.Sequential(nn.Conv1d(dim * 4, dim * 2, 3, padding=1), nn.Mish())
        self.up2 = nn.Sequential(nn.Conv1d(dim * 2, dim, 3, padding=1), nn.Mish())
        self.final_conv = nn.Conv1d(dim, transition_dim, 1)

    def forward(self, x, t):
        t_emb = self.time_mlp(t).unsqueeze(-1)
        x1 = self.down1(x) + t_emb
        x2 = self.down2(x1)
        x3 = self.down3(x2)
        x = self.up1(x3) + x2
        x = self.up2(x) + x1
        x = self.final_conv(x)
        return x

# =================================================================
# 3. æ‰©æ•£é‡‡æ ·å™¨ (ä¿®å¤è½¬åœˆé—®é¢˜)
# =================================================================
class DiffusionSampler:
    def __init__(self, model, normalization_path, device='cuda:0', horizon=64, obs_dim=26, act_dim=2):
        self.model = model
        self.device = device
        self.horizon = horizon
        self.obs_dim = obs_dim
        self.act_dim = act_dim
        self.n_timesteps = 100
        
        # åŠ è½½å½’ä¸€åŒ–å‚æ•°
        norm_data = np.load(normalization_path)
        self.mins = torch.from_numpy(norm_data['mins']).to(device)
        self.maxs = torch.from_numpy(norm_data['maxs']).to(device)
        
        # é¢„è®¡ç®—
        betas = torch.linspace(1e-4, 2e-2, self.n_timesteps).to(device)
        alphas = 1. - betas
        alphas_cumprod = torch.cumprod(alphas, dim=0)
        self.sqrt_recip_alphas = torch.sqrt(1.0 / alphas)
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)
        self.posterior_variance = betas * (1. - torch.cat([torch.tensor([1.0]).to(device), alphas_cumprod[:-1]])) / (1. - alphas_cumprod)

    def normalize(self, x):
        x_norm = (x - self.mins) / (self.maxs - self.mins)
        x_norm = 2 * x_norm - 1
        # ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘å¼ºåˆ¶ Clip åˆ° [-1, 1]ï¼Œé˜²æ­¢ OOD å¯¼è‡´è½¬åœˆ
        return torch.clamp(x_norm, -1.0, 1.0)

    def unnormalize(self, x):
        x_01 = (x + 1) / 2
        return x_01 * (self.maxs - self.mins) + self.mins

    @torch.no_grad()
    def sample(self, current_obs):
        batch_size = 1
        shape = (batch_size, self.horizon, self.obs_dim + self.act_dim)
        
        # 1. å‡†å¤‡å½“å‰è§‚æµ‹
        curr_obs_tensor = torch.from_numpy(current_obs).float().to(self.device)
        dummy_input = torch.zeros(self.obs_dim + self.act_dim).to(self.device)
        dummy_input[:self.obs_dim] = curr_obs_tensor
        
        # å½’ä¸€åŒ– + Clip
        norm_start = self.normalize(dummy_input)[:self.obs_dim]

        # 2. ä»å™ªå£°å¼€å§‹
        x = torch.randn(shape, device=self.device)
        
        # 3. å»å™ªå¾ªç¯
        for i in reversed(range(0, self.n_timesteps)):
            t = torch.full((batch_size,), i, device=self.device, dtype=torch.long)
            x_in = x.permute(0, 2, 1) 
            noise_pred = self.model(x_in, t).permute(0, 2, 1)
            
            beta_t = 1 - (self.sqrt_recip_alphas[i] ** -2)
            coeff = beta_t / self.sqrt_one_minus_alphas_cumprod[i]
            
            mean = self.sqrt_recip_alphas[i] * (x - coeff * noise_pred)
            if i > 0:
                noise = torch.randn_like(x)
                sigma = torch.sqrt(self.posterior_variance[i])
                x = mean + sigma * noise
            else:
                x = mean
            
            # ğŸ”¥ Inpainting: å¼ºåˆ¶ä¿®æ­£å½“å‰çŠ¶æ€
            x[:, 0, :self.obs_dim] = norm_start

        traj = self.unnormalize(x)
        action = traj[0, 0, self.obs_dim:] 
        return action.cpu().numpy()

# =================================================================
# 4. ä¸»ç¨‹åº (ä¸Šå¸è§†è§’ + è§†é¢‘ä¿å­˜)
# =================================================================
if __name__ == '__main__':
    # é…ç½®
    MODEL_PATH = './çœ‹lossæ›²çº¿/ppolag_256/diffuser_step_50000.pt'
    NORM_PATH = './çœ‹lossæ›²çº¿/ppolag_256/normalization.npz'
    VIDEO_PATH = './çœ‹lossæ›²çº¿/ppolag_256/diffuser_godview.mp4'
    
    device = 'cuda:0'
    
    # 1. åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = TemporalUnet(transition_dim=28, dim=256).to(device)
    
    if os.path.exists(MODEL_PATH):
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    else:
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹: {MODEL_PATH}")
        exit()
        
    sampler = DiffusionSampler(model, NORM_PATH, device=device)

    # 2. ç¯å¢ƒåˆå§‹åŒ– (ä¸Šå¸è§†è§’)
    print("æ­£åœ¨åˆå§‹åŒ–ç¯å¢ƒ (God View)...")
    # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šcamera_name='fixedfar' (ä¸Šå¸è§†è§’)
    # ğŸ”¥ğŸ”¥ğŸ”¥ å¢å¤§åˆ†è¾¨ç‡ width=1024, height=1024 è®©è§†é¢‘æ›´æ¸…æ¥š
    env = safety_gymnasium.make('SafetyPointGoal1-v0', 
                                render_mode='rgb_array', 
                                camera_name='fixedfar',  # ğŸ‘ˆ ä¸Šå¸è§†è§’
                                width=1024, 
                                height=1024)
    
    print(f"ğŸš€ å¼€å§‹ Diffuser æ§åˆ¶æµ‹è¯•...")
    obs, _ = env.reset()
    frames = []
    
    try:
        for step in range(1000): 
            if step % 50 == 0: print(f"Step {step}/500...")

            # A. è§„åˆ’
            action = sampler.sample(obs)
            
            # ğŸ” è°ƒè¯•æ‰“å°ï¼šçœ‹çœ‹æ˜¯ä¸æ˜¯ä¸€ç›´åœ¨è½¬åœˆ (Pointæœºå™¨äººçš„åŠ¨ä½œæ˜¯ [v, omega])
            # å¦‚æœ omega (ç¬¬2ç»´) å¾ˆå¤§ä¸” v (ç¬¬1ç»´) å¾ˆå°ï¼Œå°±æ˜¯åœ¨åŸåœ°è½¬
            if step % 20 == 0:
                print(f"   Action: v={action[0]:.2f}, w={action[1]:.2f}")

            # B. æ‰§è¡Œ
            next_obs, reward, cost, done, trunc, info = env.step(action)
            
            # C. æ¸²æŸ“
            frame = env.render()
            frames.append(frame)
            
            obs = next_obs
            
            if done or trunc:
                print(f"âœ¨ Episode Finished at step {step}")
                obs, _ = env.reset()
                
    except KeyboardInterrupt:
        print("æ‰‹åŠ¨åœæ­¢...")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if len(frames) > 0:
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜è§†é¢‘ ({len(frames)} å¸§) -> {VIDEO_PATH} ...")
            imageio.mimsave(VIDEO_PATH, frames, fps=30)
            print("âœ… è§†é¢‘ä¿å­˜å®Œæ¯•ï¼è¯·ä¸‹è½½æŸ¥çœ‹ã€‚")